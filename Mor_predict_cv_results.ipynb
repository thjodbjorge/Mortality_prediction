{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix, log_loss\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LinearRegression\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFE, RFECV, SelectPercentile, SelectFpr, SelectFdr, SelectFwe\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('/odinn/users/thjodbjorge/Python_functions/')\n",
    "# import Predict_functions as pf\n",
    "from Calculate_score import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/raw_with_info.csv',index_col = 'Barcode2d' )\n",
    "probe_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probe_info.csv', index_col = 'SeqId')\n",
    "\n",
    "pn_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/pn_info_Mor/pn_info_Mor_event.csv',index_col = 'Barcode2d' )\n",
    "probes_to_skip = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probes_to_skip.txt')['probe']\n",
    "\n",
    "folder = '/odinn/users/thjodbjorge/Proteomics/Mortality2/'\n",
    "feat_folder = 'Features2/'\n",
    "pred_folder = 'Predictions_cv2/'\n",
    "pred_folder_update = 'Predictions4/'\n",
    "plots = 'Plots5_plots_in_paper/'\n",
    "\n",
    "\n",
    "endpoints = ['death']\n",
    "# endpoints = ['death','Cdeath','Gdeath','Ideath','Jdeath','Otherdeath']\n",
    "# event_date = event_date_death\n",
    "time_to_event = pn_info.time_to_death\n",
    "no_event_before = pn_info.no_death_before\n",
    "for endpoint in endpoints:\n",
    "    if endpoint == 'death':\n",
    "        use_event = pn_info.event_death\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Cdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'C')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Gdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'G')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Ideath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'I')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Jdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'J')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Otherdeath':\n",
    "        use_event = pn_info.event_death & (~(pn_info.ICD_group == 'C')&~(pn_info.ICD_group == 'G')&~(pn_info.ICD_group == 'I')&~(pn_info.ICD_group == 'J'))\n",
    "        print(use_event.sum())\n",
    "\n",
    "\n",
    "y = []\n",
    "for i in range(1,19):\n",
    "    y.append(use_event & (time_to_event <= i))\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=10, shuffle=False) \n",
    "I_train_main, I_test_main = train_test_split(pn_info.index, train_size=0.7, random_state = 10)\n",
    "I_val_main, I_test_main = train_test_split(I_test_main, train_size=0.5, random_state = 10)\n",
    "\n",
    "\n",
    "file = open(folder+\"{}_keep_samples.pkl\".format('Mor'),'rb')\n",
    "keep_samples_dict = pickle.load(file)\n",
    "\n",
    "print(keep_samples_dict.keys())\n",
    "# keep_samples_keys = ['Old_18105', 'Old_60105', 'Old_6080','Old_18105_C', 'Old_18105_I', 'Old_18105_J', 'Old_18105_G','Old_18105_Other']\n",
    "# keep_samples_keys = ['Old_6080']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Old_18105'\n",
    "plot_folder = '{}_{}/'.format(endpoint,dataset)\n",
    "print(plot_folder)\n",
    "\n",
    "file = open(folder+pred_folder+\"{}_{}_predict_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "pred_dict_cv = pickle.load(file)\n",
    "# print(pred_dict_cv.keys())\n",
    "\n",
    "file = open(folder+pred_folder_update+\"{}_{}_predict_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "pred_dict_cv_update = pickle.load(file)\n",
    "\n",
    "# file = open(folder+pred_folder+\"{}_{}_predict_cv_corr.pkl\".format(endpoint,dataset),'rb')\n",
    "# pred_dict_cv_corr = pickle.load(file)\n",
    "# print(pred_dict_cv_corr.keys())\n",
    "\n",
    "# file = open(folder+pred_folder+\"{}_{}_predict_cv_MLP.pkl\".format(endpoint,dataset),'rb')\n",
    "# pred_dict_cv_MLP = pickle.load(file)\n",
    "# print(pred_dict_cv_MLP.keys())\n",
    "\n",
    "# file = open(folder+pred_folder+\"{}_{}_predict_cv_SVM.pkl\".format(endpoint,dataset),'rb')\n",
    "# pred_dict_cv_SVM = pickle.load(file)\n",
    "# print(pred_dict_cv_SVM.keys())\n",
    "\n",
    "# file = open(folder+pred_folder+\"{}_{}_predict_cv_XGB.pkl\".format(endpoint,dataset),'rb')\n",
    "# pred_dict_cv_XGB = pickle.load(file)\n",
    "# print(pred_dict_cv_XGB.keys())\n",
    "\n",
    "# pred_dict_cv = {**pred_dict_cv, **pred_dict_cv_MLP,**pred_dict_cv_XGB}  \n",
    "# pred_dict_cv = {**pred_dict_cv, **pred_dict_cv_corr}\n",
    "# print(pred_dict_cv.keys())\n",
    "print(pred_dict_cv['Old_18105_baseline2_lr_y9'][2][0][:5])\n",
    "for key,value in pred_dict_cv_update.items():\n",
    "    print(key)\n",
    "    pred_dict_cv[key] = value \n",
    "print(pred_dict_cv['Old_18105_baseline2_lr_y9'][2][0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=9\n",
    "keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "I_train = I_train_main.intersection(keep_samples)\n",
    "I_test = I_test_main.intersection(keep_samples)\n",
    "tte_train = time_to_event[I_train]\n",
    "# try: \n",
    "#     file = open(folder+pred_folder+\"{}_{}_predict_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "#     pred_dict_cv = pickle.load(file)\n",
    "\n",
    "# except:\n",
    "#     pred_dict_cv = {}\n",
    "\n",
    "score_dict = {}\n",
    "\n",
    "keys = pred_dict_cv.keys()\n",
    "# new_keys = []\n",
    "# for key in keys:\n",
    "#     if 'newy{}_'.format(k) in key:\n",
    "#         new_keys.append(key)\n",
    "# keys = new_keys\n",
    "\n",
    "# keys = ['PCEprs_4080_boruta_y9_coxl2','PCEprs_4080_boruta_y9_coxl2end']\n",
    "print(keys)\n",
    "# keys=['{}_all_y{}_lrl1'.format(dataset,k)]\n",
    "print(keys)\n",
    "bins = [0,0.075,1]\n",
    "for key in keys:\n",
    "    out = []\n",
    "    fold_num = 0\n",
    "    for train_index, test_index in kf.split(I_train):\n",
    "        fold = pred_dict_cv[key][2][fold_num]\n",
    "        numf = pred_dict_cv[key][0][fold_num]\n",
    "        y_test = y[k][I_train].iloc[test_index]\n",
    "        tte_test = tte_train.iloc[test_index]\n",
    "#         base_fold = pred_dict_cv['{}_agesex_lr_y{}'.format(dataset,k)][2][fold_num]        \n",
    "        base_fold = pred_dict_cv['{}_agesex_cox_y{}'.format(dataset,k)][2][fold_num]  \n",
    "#         y_cens_test = y_cens[k][I_train].iloc[test_index]\n",
    "#         print(key)\n",
    "        auc =[]\n",
    "        for i,case in enumerate(fold):\n",
    "#             auc.append([len(numf[i]),roc_auc_score(y_test,np.array(case).reshape(-1)),log_loss(y_test,np.array(case).reshape(-1))])\n",
    "#             auc.append([len(numf[i]),roc_auc_score(y_test[~y_cens_test],np.array(case).reshape(-1)[~y_cens_test]),log_loss(y_test[~y_cens_test],np.array(case).reshape(-1)[~y_cens_test])])\n",
    "            auc.append(len(numf[i]))\n",
    "#             auc.extend(calculate_metrics(np.array(case).reshape(-1)[~y_cens_test],np.array(base_fold[0]).reshape(-1)[~y_cens_test],y_test[~y_cens_test],bins=bins))\n",
    "            auc.extend(calculate_metrics(np.array(case).reshape(-1),np.array(base_fold[0]).reshape(-1),y_test,bins=bins))\n",
    "            auc.append(concordance_index_censored(y_test,tte_test,np.array(case).reshape(-1))[0])\n",
    "        \n",
    "        out.append(auc)\n",
    "        fold_num = fold_num+1\n",
    "    score_dict[key] = out\n",
    "#             print(len(y_test), len(case))\n",
    "f = open(folder+pred_folder+\"{}_{}_score_cv.pkl\".format(endpoint,dataset),\"wb\")\n",
    "pickle.dump(score_dict,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    file = open(folder+pred_folder+\"{}_{}_score_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "    score_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No score dict')\n",
    "\n",
    "\n",
    "# keys = pred_dict_cv.keys()\n",
    "keys = score_dict.keys()\n",
    "new_keys = []\n",
    "for key in keys:\n",
    "    if 'y{}'.format(k) in key:\n",
    "        new_keys.append(key)\n",
    "keys = new_keys\n",
    "\n",
    "# fig = plt.figure(figsize=[6,6])\n",
    "for key in keys:\n",
    "    out=score_dict[key]\n",
    "#     plt.scatter(np.array(out).mean(axis=0)[:,0],np.array(out).mean(axis=0)[:,1])\n",
    "    plt.scatter(np.array(out).mean(axis=0)[0],np.array(out).mean(axis=0)[1])\n",
    "\n",
    "lgd = plt.legend(keys,loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "# plt.savefig(folder+\"Predictions_cv/{}_{}_AUC_y{}.png\".format(endpoint,dataset,k), bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=[6,6])\n",
    "for key in keys:\n",
    "    out=score_dict[key]\n",
    "#     plt.scatter(np.array(out).mean(axis=0)[:,0],np.array(out).mean(axis=0)[:,2])\n",
    "    plt.scatter(np.array(out).mean(axis=0)[0],np.array(out).mean(axis=0)[2])\n",
    "# plt.legend(keys)\n",
    "lgd = plt.legend(keys,loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "# plt.savefig(folder+pred_folder+\"{}_{}_logloss_y{}.png\".format(endpoint,dataset,k),bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    file = open(folder+pred_folder+\"{}_{}_score_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "    score_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No score dict')\n",
    "\n",
    "\n",
    "# keys = ['PCEprs_4080_boruta_y9_coxl2','PCEprs_4080_boruta_y9_coxl2end']\n",
    "keys = score_dict.keys()\n",
    "new_keys = []\n",
    "for key in keys:\n",
    "    if 'y{}'.format(k) in key:\n",
    "        new_keys.append(key)\n",
    "keys = new_keys\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    ## AUC, Bries, logloss, IDI, NRI, AP, NRI_events, NRI_ctrl\n",
    "    df[key] = np.array(out).mean(axis=0)\n",
    "#     print(key, np.array(out).mean(axis=0)[-4], np.array(out).mean(axis=0)[-2],np.array(out).mean(axis=0)[-1])\n",
    "df_res = df.transpose()\n",
    "df_res.columns = ['Num','AUC', 'Bries', 'logloss', 'IDI', 'NRI', 'AP', 'NRI_events', 'NRI_ctrl','Cindex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "df_res.sort_values('AUC')\n",
    "# df_res.sort_values('Cindex')\n",
    "# df_res.sort_values('logloss')\n",
    "# df_res.sort_values('Bries')\n",
    "# df_res.sort_values('IDI')\n",
    "# df_res.sort_values('AP')\n",
    "# df_res.sort_values('NRI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = ['{}_tradstatprsprotein_coxelnet'.format(dataset),'{}_tradstatprsprotein_elnet'.format(dataset),'{}_tradstatprsprotein_mlp'.format(dataset),'{}_tradstatprsprotein_xgb'.format(dataset)]\n",
    "# key_names = ['Cox elnet','Elnet','MLP','XGB']\n",
    "# k = 9\n",
    "\n",
    "keys = ['{}_agesex_lr_y{}'.format(dataset,k),'{}_agesexprs_lr_y{}'.format(dataset,k), '{}_baseline2_lr_y{}'.format(dataset,k),'{}_baseline2prs_lr_y{}'.format(dataset,k)]\n",
    "key_names = ['Age+sex','Age+sex+PRS', 'Baseline','Baseline+PRS']\n",
    "# key_names = ['Age + sex', 'Baseline','Baseline \\n +PRS','Baseline \\n +Tri+Cre+Pla',\n",
    "#              'Baseline  \\n +PRS \\n +Tri+Cre+Pla','','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "out_list = []\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    out_list.append(np.array(out)[:,1])\n",
    "plt.boxplot(out_list,labels = key_names)\n",
    "plt.scatter(range(1,len(keys)+1), np.mean(np.array(out_list),axis=1))\n",
    "plt.grid()\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Model')\n",
    "\n",
    "plt.title(' CV {}-Year Mortality'.format(k+1))\n",
    "# plt.show()\n",
    "\n",
    "if 1:\n",
    "    plt.savefig(folder+plots+plot_folder+'{}_{}_baselineprscv_AUC_y{}.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "#     plt.savefig(folder+plots +plot_folder+'{}_{}_baselinecv_AUC_y{}_all.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "#     plt.savefig(folder+plots +plot_folder+'{}_{}_baselinecv_AUC_y{}_all_new.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[12,6])\n",
    "out_list = []\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    out_list.append(np.array(out)[:,2])\n",
    "\n",
    "#     plt.xticks(rotation=0)\n",
    "#     plt.xlabel('Model')\n",
    "plt.boxplot(out_list,labels = key_names)\n",
    "plt.grid()\n",
    "plt.ylabel('Bries')\n",
    "plt.title(' CV {}-Year Mortality'.format(k+1))\n",
    "# if 1:\n",
    "#     plt.savefig(folder+plots +plot_folder+'{}_{}_baselinecv_Bries_y{}_use.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "#     plt.savefig(folder+plots +plot_folder+'{}_{}_baselinecv_Bries_y{}_all.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "#     plt.savefig(folder+plots +plot_folder+'{}_{}_baselinecv_Bries_y{}_all_new.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[10,6])\n",
    "out_list = []\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    out_list.append(np.array(out)[:,4])\n",
    "\n",
    "#     plt.xticks(rotation=0)\n",
    "#     plt.xlabel('Model')\n",
    "plt.boxplot(out_list,labels = key_names)\n",
    "plt.ylabel('IDI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of modeling methods for protein model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=4\n",
    "keys = ['{}_agesexboruta_elnet_y{}'.format(dataset,k),'{}_agesexboruta_l1_y{}'.format(dataset,k), \n",
    "        '{}_agesexboruta_l2_y{}'.format(dataset,k),'{}_agesexboruta_coxelnet_y{}'.format(dataset,k),\n",
    "       '{}_agesexboruta_xgb_y{}'.format(dataset,k),'{}_agesexboruta_mlp_y{}'.format(dataset,k)]\n",
    "key_names = ['Elnet', 'L1','L2' ,'Cox Elnet','XGB','MLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "out_list = []\n",
    "key_num = []\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    out_list.append(np.array(out)[:,1])\n",
    "    key_num.append(key_names[i] +'\\n {:0.0f}'.format(np.array(out)[:,0][0]))\n",
    "plt.boxplot(out_list,labels = key_num)\n",
    "plt.scatter(range(1,len(keys)+1), np.mean(np.array(out_list),axis=1))\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Model / # proteins')\n",
    "plt.title(' CV {} Year Mortality'.format(k+1))\n",
    "plt.grid()\n",
    "\n",
    "if 1:\n",
    "    plt.savefig(folder+plots +plot_folder+'{}_{}_modelscv_all_AUC_y{}.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "out_list = []\n",
    "num_list = []\n",
    "key_num = []\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    out_list.append(np.array(out)[:,2])\n",
    "    key_num.append(key_names[i] +'\\n {:0.0f}'.format(np.array(out)[:,0][0]))\n",
    "#     plt.xticks(rotation=0)\n",
    "plt.xlabel('Model/ # proteins')\n",
    "plt.boxplot(out_list,labels = key_num)\n",
    "plt.scatter(range(1,len(keys)+1), np.mean(np.array(out_list),axis=1))\n",
    "plt.ylabel('Bries')\n",
    "plt.title(' CV {} Year Mortality'.format(k+1))\n",
    "plt.grid()\n",
    "if 1:\n",
    "    plt.savefig(folder+plots +plot_folder+'{}_{}_modelscv_all_Bries_y{}.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "out_list = []\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    out_list.append(np.array(out)[:,-1])\n",
    "plt.boxplot(out_list,labels = key_names)\n",
    "plt.scatter(range(1,len(keys)+1), np.mean(np.array(out_list),axis=1))\n",
    "plt.title(' CV {} Year Mortality'.format(k+1))\n",
    "plt.ylabel('C-index')\n",
    "plt.xlabel('Model/ # proteins')\n",
    "plt.grid()\n",
    "if 1:\n",
    "    plt.savefig(folder+plots +plot_folder+'{}_{}_modelscv_all_Cind_y{}.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "out_list = []\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    out_list.append(np.array(out)[:,6])\n",
    "plt.boxplot(out_list,labels = key_names)\n",
    "plt.scatter(range(1,len(keys)+1), np.mean(np.array(out_list),axis=1))\n",
    "plt.title(' CV {} Year Mortality'.format(k+1))\n",
    "plt.ylabel('Average Precision')\n",
    "plt.xlabel('Model/ # proteins')\n",
    "plt.grid()\n",
    "if 1:\n",
    "    plt.savefig(folder+plots +plot_folder+'{}_{}_modelscv_all_AP_y{}.png'.format(endpoint,dataset,k),bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
