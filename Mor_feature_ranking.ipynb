{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix, log_loss\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFE, RFECV, SelectPercentile, SelectFpr, SelectFdr, SelectFwe\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif, SelectFdr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import lifelines as ll\n",
    "# from lifelines.utils.sklearn_adapter import sklearn_adapter\n",
    "# CoxRegression = sklearn_adapter(ll.CoxPHFitter, event_col = 'event')\n",
    "import sys\n",
    "sys.path.append('/odinn/users/thjodbjorge/Python_functions/')\n",
    "import Predict_functions as pf\n",
    "from Calculate_score import calculate_metrics, make_class_table\n",
    "from R_functions import R_pROC,R_pROC_compareROC,R_pROC_compareROC_boot, R_pROC_AUC, R_timeROC, R_timeROC_CI, R_timeROC_pval, R_NRIbin,R_NRIcens,R_NRIcensipw, R_censROC, R_hoslem, R_Greenwood_Nam\n",
    "\n",
    "raw_data = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/raw_with_info.csv',index_col = 'Barcode2d' )\n",
    "probe_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probe_info.csv', index_col = 'SeqId')\n",
    "\n",
    "pn_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/pn_info_Mor/pn_info_Mor_event.csv',index_col = 'Barcode2d' )\n",
    "probes_to_skip = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probes_to_skip.txt')['probe']\n",
    "nopro = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/no_protein_probes.txt', header = None)[0] # non-proten probes that were included \n",
    "probes_to_skip = set(probes_to_skip).union(set(nopro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/odinn/users/thjodbjorge/Proteomics/Mortality2/'\n",
    "feat_folder = 'Features2/'\n",
    "pred_folder = 'Predictions3/'\n",
    "plots = 'Plots2/'\n",
    "save_plot = True\n",
    "\n",
    "endpoints = ['death']\n",
    "# endpoints = ['death','Cdeath','Gdeath','Ideath','Jdeath','Otherdeath']\n",
    "# event_date = event_date_death\n",
    "time_to_event = pn_info.time_to_death\n",
    "no_event_before = pn_info.no_death_before\n",
    "for endpoint in endpoints:\n",
    "    if endpoint == 'death':\n",
    "        use_event = pn_info.event_death\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Cdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'C')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Gdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'G')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Ideath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'I')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Jdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'J')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Otherdeath':\n",
    "        use_event = pn_info.event_death & (~(pn_info.ICD_group == 'C')&~(pn_info.ICD_group == 'G')&~(pn_info.ICD_group == 'I')&~(pn_info.ICD_group == 'J'))\n",
    "        print(use_event.sum())\n",
    "\n",
    "y = []\n",
    "for i in range(1,19):\n",
    "    y.append(use_event & (time_to_event <= i))\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=10, shuffle=False) \n",
    "I_train_main, I_test_main = train_test_split(pn_info.index, train_size=0.7, random_state = 10)\n",
    "# I_val_main, I_test_main = train_test_split(I_test_main, train_size=0.5, random_state = 10)\n",
    "\n",
    "\n",
    "file = open(folder+\"{}_keep_samples.pkl\".format('Mor'),'rb')\n",
    "keep_samples_dict = pickle.load(file)\n",
    "\n",
    "dataset = 'Old_60105'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_prediction = True\n",
    "if do_prediction:\n",
    "\n",
    "    keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "    I_train = I_train_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "    I_test = I_test_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "\n",
    "    print('Training set: {}, MI within 15: {}, 10: {}, 5: {}, 2: {}'.format(len(I_train),y[14][I_train].sum(),y[9][I_train].sum(),y[4][I_train].sum(),y[1][I_train].sum()))\n",
    "    print('Test set: {}, MI within 15: {}, 10: {}, 5: {}, 2: {}'.format(len(I_test),y[14][I_test].sum(),y[9][I_test].sum(),y[4][I_test].sum(),y[1][I_test].sum()))\n",
    "\n",
    "        # ### Select data and normalize\n",
    "\n",
    "    X = np.log(raw_data.iloc[:,16:].drop(probes_to_skip,axis=1))\n",
    "\n",
    "    all_protein = X.columns\n",
    "    X['sex'] = pn_info[['sex']].values-1\n",
    "    X['age'] = pn_info[['Age_at_sample_collection_2']].values\n",
    "\n",
    "    X['age2'] = X['age']**2\n",
    "#     X['age3'] = X['age']**3\n",
    "    X['agesex'] = X['age']*X['sex']\n",
    "    X['age2sex'] = X['age2']*X['sex']\n",
    "        \n",
    "    agesex = ['age','sex','agesex','age2','age2sex']\n",
    "       \n",
    "    X['lnage'] = np.log(X['age'])\n",
    "    X['lnage2'] = X['lnage']**2\n",
    "    \n",
    "    X['PAD'] = pn_info['PAD']\n",
    "    no_bmi = (X['PAD'].isna())\n",
    "    no_bmi_ind = X[no_bmi].index\n",
    "    X.loc[I_train.intersection(no_bmi_ind),'PAD'] = X.loc[I_train].PAD.mean()\n",
    "    X.loc[I_test.intersection(no_bmi_ind),'PAD'] = X.loc[I_test].PAD.mean()\n",
    "    \n",
    "    \n",
    "    X['CAD'] = ~pn_info.no_CAD_before\n",
    "    X['MI'] = ~pn_info.no_MI_before\n",
    "    X['cancer'] = pn_info.cancer_margin\n",
    "    X['ApoB'] = X['SeqId.2797-56']\n",
    "    X['Smoker'] = pn_info['Smoker'].astype(int).values\n",
    "    X['diabetes'] = pn_info['T2D'].astype(int).values\n",
    "    X['HTN_treated'] = pn_info[['HTN_treated']].astype(int).values\n",
    "#     X['statin'] = pn_info['statin'].astype(int).values\n",
    "    X['statin'] = pn_info['statin_estimate_unsure'].astype(int).values\n",
    "    X['ApoBstatin']  = X['ApoB']*X['statin']\n",
    "    \n",
    "    X['cancer1y']  = pn_info['cancer1y']\n",
    "    X['cancer5y']  = pn_info['cancer5y']\n",
    "\n",
    "    X['GDF15'] = X['SeqId.4374-45'].copy()\n",
    "    X['GDF152'] = X['GDF15']**2\n",
    "    X['GDF15age']  = X['GDF15']*X['age']\n",
    "    X['GDF15sex']  = X['GDF15']*X['sex']\n",
    "    \n",
    "    X['bmi'] = pn_info['bmi']\n",
    "\n",
    "    no_bmi = (X['bmi'].isna())\n",
    "    no_bmi_ind = X[no_bmi].index\n",
    "#     X.loc[no_bmi_ind,'bmi'] = X.loc[I_train].bmi.mean()\n",
    "    X.loc[I_train.intersection(no_bmi_ind),'bmi'] = X.loc[I_train].bmi.mean()       \n",
    "    X.loc[I_test.intersection(no_bmi_ind),'bmi'] = X.loc[I_test].bmi.mean()   \n",
    "    \n",
    "    X['bmi2'] = X['bmi']*X['bmi']\n",
    "    \n",
    "    X['Platelets'] = pn_info['Platelets']\n",
    "    no_p = (X['Platelets'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Platelets'] = X.loc[I_train].Platelets.mean()\n",
    "    X.loc[I_test.intersection(no_p_ind),'Platelets'] = X.loc[I_test].Platelets.mean()\n",
    "    X['Platelets2'] = X['Platelets']*X['Platelets']\n",
    "    \n",
    "    X['Creatinine'] = pn_info['Creatinine']\n",
    "    no_p = (X['Creatinine'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Creatinine'] = X.loc[I_train].Creatinine.mean()\n",
    "    X.loc[I_test.intersection(no_p_ind),'Creatinine'] = X.loc[I_test].Creatinine.mean()\n",
    "    \n",
    "    X['Triglycerides'] = pn_info['Triglycerides']\n",
    "    no_p = (X['Triglycerides'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Triglycerides'] = X.loc[I_train].Triglycerides.mean()    \n",
    "    X.loc[I_test.intersection(no_p_ind),'Triglycerides'] = X.loc[I_test].Triglycerides.mean()   \n",
    "    \n",
    "\n",
    "    X['bmiage'] = X['bmi']*X['age']\n",
    "    X['bmisex'] = X['bmi']*X['sex']\n",
    "    X['bmi2age'] = X['bmi2']*X['age']\n",
    "    X['bmi2sex'] = X['bmi2']*X['sex']\n",
    "    X['PADage'] = X['PAD']*X['age']\n",
    "    X['PADsex'] = X['PAD']*X['sex']\n",
    "    \n",
    "    X['ApoBage']  = X['ApoB']*X['age']\n",
    "    X['Smokerage'] = X['Smoker']*X['age']\n",
    "    X['diabetesage'] = X['diabetes']*X['age'] \n",
    "    X['statinage'] = X['statin']*X['age']\n",
    "    X['CADage'] = X['CAD']*X['age']\n",
    "    X['MIage'] = X['MI'] * X['age']\n",
    "    X['HTN_treatedage'] =  X['age']*X['HTN_treated']    \n",
    "    X['cancerage'] = X['age']*X['cancer']\n",
    "    \n",
    "    X['Plateletsage'] = X['Platelets']*X['age']\n",
    "    X['Creatinineage'] = X['Creatinine']*X['age']\n",
    "    X['Triglyceridesage'] = X['Triglycerides']*X['age']    \n",
    "    X['Platelets2age'] = X['Platelets2']*X['age']\n",
    "    \n",
    "    X['cancer1yage'] = X['cancer1y']*X['age'] \n",
    "    X['cancer5yage'] = X['cancer5y']*X['age']     \n",
    "    \n",
    "    X['ApoBsex']  = X['ApoB']*X['sex']\n",
    "    X['Smokersex'] = X['Smoker']*X['sex']\n",
    "    X['diabetessex'] = X['diabetes']*X['sex'] \n",
    "    X['statinsex'] = X['statin']*X['sex']\n",
    "    X['CADsex'] = X['CAD']*X['sex']\n",
    "    X['MIsex'] = X['MI'] * X['sex']\n",
    "    X['HTN_treatedsex'] =  X['sex']*X['HTN_treated']   \n",
    "    X['cancersex'] = X['sex']*X['cancer']\n",
    "    \n",
    "    X['Plateletssex'] = X['Platelets']*X['sex']\n",
    "    X['Creatininesex'] = X['Creatinine']*X['sex']\n",
    "    X['Triglyceridessex'] = X['Triglycerides']*X['sex']        \n",
    "    \n",
    "    X = X.join(pd.get_dummies(pn_info['agebin'],drop_first = True,prefix='age'))\n",
    "    X['ageage2'] = X['age']*X['age_2.0']\n",
    "    X['ageage3'] = X['age']*X['age_3.0']\n",
    "    X['ageage4'] = X['age']*X['age_4.0']\n",
    "    \n",
    "    agebins = ['age_2.0','age_3.0','age_4.0', 'ageage2','ageage3','ageage4']\n",
    "    agebinssex = [s+'sex' for s in agebins]\n",
    "    X[agebinssex] = (X[agebins].transpose()*X['sex']).transpose()    \n",
    "    \n",
    "    \n",
    "    PRS = ['nonHDL_prs', 'HT_prs', 'CAD_prs', 'Cancer_prs', 'Stroke2_prs', 'alz_Jansen',\n",
    "       'pgc_adhd_2017', 'PD_Nalls_2018', 'edu_160125', 'dep_2018', 'bpd_2018',\n",
    "       'giant_bmi', 'schizo_clozuk', 'iq_2018', 'ipsych_pgc_aut_2017',\n",
    "       'pgc_Anorexia_2019']\n",
    "    X[PRS] = pn_info[PRS]\n",
    "    \n",
    "    trad = ['ApoB','Smoker','diabetes','HTN_treated','statin','CAD','MI','bmi','bmi2']\n",
    "    tradage = ['ApoBage','Smokerage','diabetesage','CADage','MIage','HTN_treatedage','bmiage']\n",
    "    tradsex = ['ApoBsex','Smokersex','diabetessex','CADsex','MIsex','HTN_treatedsex','bmisex']\n",
    "    \n",
    "    tradcoxR = ['Smoker','Smokersex','diabetes','diabetesage','HTN_treated','HTN_treatedage','MI','MIage','CAD','bmi','bmiage','statin','statinage']\n",
    "    tradextralog = ['Smokersex','diabetessex','CADsex','CADage','MIage','HTN_treatedage','bmiage','statinage','bmi2age','ApoBstatin']\n",
    "    tradextralognosex = ['CADage','MIage','HTN_treatedage','bmiage']\n",
    "    tradblood = ['Creatinine','Triglycerides','Platelets','Platelets2','Plateletsage','Creatinineage','Platelets2age']\n",
    "    tradcancer = ['cancer','cancerage']    \n",
    "    extra_cancer = ['cancer1y','cancer5y','cancer1yage','cancer5yage']\n",
    "\n",
    "\n",
    "    X_train = X.loc[I_train]\n",
    "    X_test = X.loc[I_test]\n",
    "\n",
    "    train_mean = X_train.mean()\n",
    "    train_std = X_train.std()\n",
    "\n",
    "    X_train = (X_train-train_mean)/train_std\n",
    "    X_test = (X_test-train_mean)/train_std\n",
    "\n",
    "        ## For survival analysis    \n",
    "    X_train['event'] = use_event[I_train]\n",
    "    X_test['event'] = use_event[I_test]\n",
    "\n",
    "    tte_train = time_to_event[I_train]\n",
    "    tte_test = time_to_event[I_test]\n",
    "\n",
    "    ysurv_train = pd.DataFrame()\n",
    "    ysurv_train['event'] = use_event[I_train]\n",
    "    ysurv_train['time_to_event'] = time_to_event[I_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = 'Old_6080'\n",
    "# try: \n",
    "#     file = open(folder+pred_folder+\"{}_{}_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "#     pred_dict = pickle.load(file)\n",
    "# except:\n",
    "#     pred_dict = {}\n",
    "# pred_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_plot=9\n",
    "k = k_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file = open(folder+feat_folder+\"{}_{}_features.pkl\".format(endpoint,dataset),'rb')\n",
    "features_dict = pickle.load(file)           \n",
    "\n",
    "#         boruta = sorted(features_dict['{}_boruta_y{}'.format(dataset,k)])\n",
    "file = open(folder+pred_folder + \"{}_{}_bootstrap.pkl\".format(endpoint,dataset),'rb')\n",
    "bootstrap_dict = pickle.load(file)\n",
    "  \n",
    "boot = np.abs(np.array(bootstrap_dict['{}_y{}_asprotein_l1_boot'.format(dataset,k)])[:,0,:])\n",
    "feat =  sorted(features_dict['{}_boruta_y{}'.format(dataset,k)])\n",
    "    \n",
    "\n",
    "plot_folder = '{}_{}/'.format(endpoint,dataset)\n",
    "\n",
    "keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "I_train = I_train_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "I_test = I_test_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "\n",
    "y_train = y[k][I_train]\n",
    "y_test= y[k][I_test]\n",
    "\n",
    "print(bootstrap_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.sum(boot>0,axis=0)\n",
    "rank = np.mean(boot,axis=0)\n",
    "df_feat = pd.DataFrame([feat, num[-len(feat):], rank[-len(feat):]]).transpose()\n",
    "pd.options.display.max_rows = 100\n",
    "feat_sorted = df_feat.sort_values(2,ascending=False).sort_values(1, ascending=False)\n",
    "nump = len(feat_sorted)\n",
    "print(nump)\n",
    "feat_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = False\n",
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder + \"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_dict = {}\n",
    "\n",
    "if do_training:\n",
    "    k=k_plot\n",
    "    for i in range(0,100):\n",
    "        print(feat_sorted.iloc[:i,0])  \n",
    "        try:\n",
    "            feat = []        \n",
    "            feat.extend(agesex)\n",
    "            feat.extend(feat_sorted.iloc[:i,0])\n",
    "            \n",
    "            pred_dict['{}_y{}_agesex_l1bootp{}_elnet'.format(dataset,k,i)] = pf.predict(feat=feat,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,model_type='lrl1l2')\n",
    "            f = open(folder+pred_folder+\"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),\"wb\")\n",
    "            pickle.dump(pred_dict,f)\n",
    "            f.close()\n",
    "            print('Done i = ',i)\n",
    "        except Exception as e:\n",
    "            print('Fail boruta', i)\n",
    "            print(e)\n",
    "pred_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sorted_ind = [f[6:] for f in feat_sorted[0]]\n",
    "# pd.DataFrame([feat_sorted[0] probe_info.loc[feat_sorted_ind,'Target']]).transpose()\n",
    "feat_sorted['Target'] = probe_info.loc[feat_sorted_ind,'Target'].values\n",
    "feat_sorted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file = open(folder+feat_folder+\"{}_{}_features.pkl\".format(endpoint,dataset),'rb')\n",
    "features_dict = pickle.load(file)           \n",
    "\n",
    "#         boruta = sorted(features_dict['{}_boruta_y{}'.format(dataset,k)])\n",
    "file = open(folder+pred_folder + \"{}_{}_bootstrap.pkl\".format(endpoint,dataset),'rb')\n",
    "bootstrap_dict = pickle.load(file)\n",
    "  \n",
    "boot = np.abs(np.array(bootstrap_dict['{}_y{}_asprotein_l1_boot1000'.format(dataset,k)])[:,0,:])\n",
    "feat =  sorted(features_dict['{}_boruta_y{}'.format(dataset,k)])\n",
    "    \n",
    "\n",
    "plot_folder = '{}_{}/'.format(endpoint,dataset)\n",
    "\n",
    "keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "I_train = I_train_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "I_test = I_test_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "\n",
    "y_train = y[k][I_train]\n",
    "y_test= y[k][I_test]\n",
    "\n",
    "print(bootstrap_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.sum(boot>0,axis=0)\n",
    "rank = np.mean(boot,axis=0)\n",
    "df_feat = pd.DataFrame([feat, num[-len(feat):], rank[-len(feat):]]).transpose()\n",
    "pd.options.display.max_rows = 100\n",
    "feat_sorted = df_feat.sort_values(2,ascending=False).sort_values(1, ascending=False)\n",
    "nump = len(feat_sorted)\n",
    "print(nump)\n",
    "feat_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = True\n",
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder + \"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_dict = {}\n",
    "\n",
    "if do_training:\n",
    "    k=k_plot\n",
    "    for i in range(0,100):\n",
    "        print(feat_sorted.iloc[:i,0])  \n",
    "        try:\n",
    "            feat = []        \n",
    "            feat.extend(agesex)\n",
    "            feat.extend(feat_sorted.iloc[:i,0])\n",
    "            \n",
    "            pred_dict['{}_y{}_agesex_l1boot1000p{}_l2'.format(dataset,k,i)] = pf.predict(feat=feat,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,model_type='lrl2')\n",
    "            f = open(folder+pred_folder+\"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),\"wb\")\n",
    "            pickle.dump(pred_dict,f)\n",
    "            f.close()\n",
    "            print('Done i = ',i)\n",
    "        except Exception as e:\n",
    "            print('Fail boruta', i)\n",
    "            print(e)\n",
    "pred_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sorted_ind = [f[6:] for f in feat_sorted[0]]\n",
    "# pd.DataFrame([feat_sorted[0] probe_info.loc[feat_sorted_ind,'Target']]).transpose()\n",
    "feat_sorted['Target'] = probe_info.loc[feat_sorted_ind,'Target'].values\n",
    "feat_sorted['Target_name'] = probe_info.loc[feat_sorted_ind,'TargetFullName'].values\n",
    "feat_sorted['Gene_name'] = probe_info.loc[feat_sorted_ind,'GeneName'].values\n",
    "feat_sorted['Uniprot'] = probe_info.loc[feat_sorted_ind,'UniProt Full Name'].values\n",
    "feat_sorted['Uniprot2'] = probe_info.loc[feat_sorted_ind,'Uniprot Short Names'].values\n",
    "feat_sorted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Old_18105'\n",
    "file = open(folder+pred_folder + \"{}_{}_forward.pkl\".format(endpoint,dataset),'rb')\n",
    "# file = open(folder+pred_folder + \"{}_{}_forward_noGDF15.pkl\".format(endpoint,dataset),'rb')\n",
    "# file = open(folder+pred_folder + \"{}_{}_forward_noGDF15HE4.pkl\".format(endpoint,dataset),'rb')\n",
    "bootstrap_dict = pickle.load(file)\n",
    "bootstrap_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = k_plot\n",
    "k=4\n",
    "boot = bootstrap_dict['{}_y{}_asprotein_lr'.format(dataset,k)]\n",
    "# boot = bootstrap_dict['{}_y{}_baselineprotein_lr'.format(dataset,k)]\n",
    "# boot = bootstrap_dict['Old_18105_asprotein_lr_boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_df = pd.DataFrame(boot[1])\n",
    "# boot_df.set_index(0,inplace=True)\n",
    "# boot_df.sort_values(1)\n",
    "display(boot_df.head())\n",
    "feat_sorted = boot_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boot_df.sort_values(1)\n",
    "# feat_sorted = list(boot_df.mean(axis=1).sort_values().index)\n",
    "feat_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# try: \n",
    "#     file = open(folder+pred_folder + \"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "#     pred_dict = pickle.load(file)\n",
    "# except:\n",
    "#     print('No test predictions')\n",
    "#     pred_dict = {}\n",
    "# pred_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = True\n",
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder + \"{}_{}_fewp_noGDF15_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_dict = {}\n",
    "print(pred_dict.keys())\n",
    "    \n",
    "if do_training:\n",
    "    k=k_plot\n",
    "    y_train = y[k][I_train]\n",
    "    y_test = y[k][I_test]    \n",
    "    print(k)\n",
    "    for i in range(0,101):\n",
    "        print(feat_sorted[:i])  \n",
    "        try:\n",
    "            feat = []        \n",
    "            feat.extend(agesex)\n",
    "            feat.extend(feat_sorted[:i])\n",
    "            \n",
    "            pred_dict['{}_y{}_agesex_forwardp{}_l2'.format(dataset,k,i)] = pf.predict(feat=feat,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,model_type='lrl2')\n",
    "#             f = open(folder+pred_folder+\"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),\"wb\")\n",
    "            f = open(folder+pred_folder+\"{}_{}_fewp_noGDF15_predict.pkl\".format(endpoint,dataset),\"wb\")\n",
    "            pickle.dump(pred_dict,f)\n",
    "            f.close()\n",
    "            print('Done i = ',i)\n",
    "        except Exception as e:\n",
    "            print('Fail boruta', i)\n",
    "            print(e)\n",
    "pred_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# do_training = True\n",
    "\n",
    "# try: \n",
    "#     file = open(folder+pred_folder + \"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "# #     file = open(folder+pred_folder + \"{}_{}_fewpnoGDF15_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "#     pred_dict = pickle.load(file)\n",
    "# except:\n",
    "#     print('No test predictions')\n",
    "#     pred_dict = {}\n",
    "# print(pred_dict.keys())\n",
    "\n",
    "# if do_training:\n",
    "#     for k in [0,2,3,5,6,7,8,10,11,12,13,14]:\n",
    "#         print(k)\n",
    "#         boot = bootstrap_dict['{}_y{}_asprotein_lr'.format(dataset,k)]\n",
    "#         boot_df = pd.DataFrame(boot[1])\n",
    "#         display(boot_df.head())\n",
    "#         feat_sorted = boot_df[0]\n",
    "        \n",
    "#         y_train = y[k][I_train]\n",
    "#         y_test = y[k][I_test]    \n",
    "#         print(k)\n",
    "#         for i in range(0,101):\n",
    "#             print(feat_sorted[:i])  \n",
    "#             try:\n",
    "#                 feat = []        \n",
    "#                 feat.extend(agesex)\n",
    "#                 feat.extend(feat_sorted[:i])\n",
    "\n",
    "#                 pred_dict['{}_y{}_agesex_forwardp{}_l2'.format(dataset,k,i)] = pf.predict(feat=feat,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,model_type='lrl2')\n",
    "#                 f = open(folder+pred_folder+\"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),\"wb\")\n",
    "# #                 f = open(folder+pred_folder+\"{}_{}_fewpnoGDF15_predict.pkl\".format(endpoint,dataset),\"wb\")\n",
    "#                 pickle.dump(pred_dict,f)\n",
    "#                 f.close()\n",
    "#                 print('Done i = ',i)\n",
    "#             except Exception as e:\n",
    "#                 print('Fail boruta', i)\n",
    "#                 print(e)\n",
    "# pred_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(folder+pred_folder + \"{}_{}_forward.pkl\".format(endpoint,dataset),'rb')\n",
    "bootstrap_dict = pickle.load(file)\n",
    "\n",
    "bootstrap_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boot = bootstrap_dict['Old_18105_asprotein_lr']\n",
    "boot = bootstrap_dict['{}_y{}_asprotein_lr_boot'.format(dataset,k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.sort_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.mean(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boot.sort_values(1)\n",
    "feat_sorted = list(boot.mean(axis=1).sort_values().index)\n",
    "feat_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = True\n",
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder + \"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_dict = {}\n",
    "\n",
    "if do_training:\n",
    "    k=k_plot\n",
    "    y_train = y[k][I_train]\n",
    "    y_test = y[k][I_test]    \n",
    "    \n",
    "    for i in range(0,100):\n",
    "        print(feat_sorted[:i])  \n",
    "        try:\n",
    "            feat = []        \n",
    "            feat.extend(agesex)\n",
    "            feat.extend(feat_sorted[:i])\n",
    "            \n",
    "            pred_dict['{}_y{}_agesex_forward_bootp{}_l2'.format(dataset,k,i)] = pf.predict(feat=feat,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,model_type='lrl2')\n",
    "            f = open(folder+pred_folder+\"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),\"wb\")\n",
    "            pickle.dump(pred_dict,f)\n",
    "            f.close()\n",
    "            print('Done i = ',i)\n",
    "        except Exception as e:\n",
    "            print('Fail boruta', i)\n",
    "            print(e)\n",
    "pred_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sorted_ind = [f[6:] for f in feat_sorted]\n",
    "\n",
    "pd.DataFrame([feat_sorted, probe_info.loc[feat_sorted_ind,'Target']]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backwards selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(folder+pred_folder + \"{}_{}_forward.pkl\".format(endpoint,dataset),'rb')\n",
    "bootstrap_dict = pickle.load(file)\n",
    "bootstrap_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = bootstrap_dict['{}_y{}_asprotein_RFElr'.format(dataset,k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sorted = feat[5:].sort_values(0).index\n",
    "feat_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = True\n",
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder + \"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_dict = {}\n",
    "\n",
    "if do_training:\n",
    "    k=k_plot\n",
    "    y_train = y[k][I_train]\n",
    "    y_test = y[k][I_test]    \n",
    "    \n",
    "    for i in range(0,100):\n",
    "        print(feat_sorted[:i])  \n",
    "        try:\n",
    "            feat = []        \n",
    "            feat.extend(agesex)\n",
    "            feat.extend(feat_sorted[:i])\n",
    "            \n",
    "            pred_dict['{}_y{}_agesex_backward_p{}_l2'.format(dataset,k,i)] = pf.predict(feat=feat,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,model_type='lrl2')\n",
    "            f = open(folder+pred_folder+\"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),\"wb\")\n",
    "            pickle.dump(pred_dict,f)\n",
    "            f.close()\n",
    "            print('Done i = ',i)\n",
    "        except Exception as e:\n",
    "            print('Fail boruta', i)\n",
    "            print(e)\n",
    "pred_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_prediction = True\n",
    "try: \n",
    "#     file = open(folder+pred_folder + \"{}_{}_fewp_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "    file = open(folder+pred_folder + \"{}_{}_fewp_noGDF15_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_dict = {}\n",
    "\n",
    "try: \n",
    "#     file = open(folder+pred_folder + \"{}_{}_fewp_test_prediction.pkl\".format(endpoint,dataset),'rb')\n",
    "    file = open(folder+pred_folder + \"{}_{}_fewp_noGDF15_test_prediction.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_test_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_test_dict = {}\n",
    "\n",
    "keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "I_train = I_train_main.intersection(keep_samples)\n",
    "I_test = I_test_main.intersection(keep_samples)\n",
    "    \n",
    "# k = k_plot\n",
    "# k=9\n",
    "if do_prediction:\n",
    "#     y_train = y[k][I_train]\n",
    "#     y_test = y[k][I_test]\n",
    "\n",
    "#             model_key = '{}_boruta_y9_coxl2'.format(dataset)\n",
    "    model_keys = pred_dict.keys()\n",
    "    for model_key in model_keys:\n",
    "        print(model_key)\n",
    "        model = pred_dict[model_key][0]\n",
    "        feat = pred_dict[model_key][3]\n",
    "\n",
    "        pred_test = model.predict_proba(X_test[feat])[:,1]\n",
    "        pred_test_dict[model_key] = pred_test\n",
    "\n",
    "    f = open(folder+pred_folder+\"{}_{}_fewp_noGDF15_test_prediction.pkl\".format(endpoint,dataset),\"wb\")\n",
    "    pickle.dump(pred_test_dict,f)\n",
    "    f.close()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERY_SMALL_SIZE = 12\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=VERY_SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward selection testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=k_plot\n",
    "# k=1\n",
    "# k=\n",
    "k2=k+1\n",
    "\n",
    "nump = 101 \n",
    "K = [k]\n",
    "NRI_low = np.zeros([nump,5])\n",
    "NRI_middle =  np.zeros([nump,5])\n",
    "NRI_high =  np.zeros([nump,5])\n",
    "IDI =  np.zeros([nump,5])\n",
    "AUC =  np.zeros([nump,5])\n",
    "AUC_CI = []\n",
    "NRI_low_CI = []\n",
    "NRI_middle_CI = []\n",
    "NRI_high_CI = []\n",
    "out_list = []\n",
    "for j,k in enumerate(K):\n",
    "\n",
    "    for i in range(nump):\n",
    "        for l in range(1):\n",
    "            pred = pd.DataFrame(pred_test_dict['{}_y{}_agesex_forwardp{}_l2'.format(dataset,k,i)],index=I_test)[0]\n",
    "            baseline = pd.DataFrame(pred_test_dict['{}_y{}_agesex_forwardp0_l2'.format(dataset,k)],index=I_test)[0]\n",
    "            \n",
    "#             pred = pd.DataFrame(pred_test_dict['{}_y{}_agesexp{}_elnet'.format(dataset,k,i)],index=I_test)[0]\n",
    "#             baseline = pd.DataFrame(pred_test_dict['{}_y{}_agesexp0_elnet'.format(dataset,k)],index=I_test)[0]\n",
    "#             pred = pd.DataFrame(pred_test_dict['predy{}_{}_tradprs_boot_forwardp{}_coxl2'.format(k,dataset,i)][0],index=I_test)[0]\n",
    "#             baseline = pd.DataFrame(pred_test_dict['predy{}_{}_tradprs_boot_forwardp0_coxl2'.format(k,dataset)][0],index=I_test)[0]\n",
    "\n",
    "            out = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.3,1])\n",
    "            out_list.append(out)\n",
    "            NRI_low[i,l] = out[4]\n",
    "            NRI_middle[i,l] = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.5,1])[4]\n",
    "            NRI_high[i,l] = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.7,1])[4]\n",
    "            IDI[i,l] = out[3]\n",
    "            AUC[i,l] = out[0]\n",
    "            \n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.3)\n",
    "#             NRI_low_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.5)\n",
    "#             NRI_middle_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.7)\n",
    "#             NRI_high_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "            \n",
    "            AUC_CI.append(R_pROC_AUC(y[k][I_test],pred))\n",
    "AUC_CI = np.array(AUC_CI)\n",
    "# NRI_low_CI = np.array(NRI_low_CI)\n",
    "# NRI_middle_CI = np.array(NRI_middle_CI)\n",
    "# NRI_high_CI = np.array(NRI_high_CI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(folder+pred_folder + \"{}_{}_forward_noGDF15.pkl\".format(endpoint,dataset),'rb')\n",
    "bootstrap_dict = pickle.load(file)\n",
    "boot = bootstrap_dict['{}_y{}_asprotein_lr'.format(dataset,k)]\n",
    "\n",
    "boot = pd.DataFrame(boot[1])\n",
    "boot = boot.sort_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(out_list,columns = ['AUC', 'Bries', 'logloss', 'IDI', 'NRI', 'AP', 'NRI_events', 'NRI_ctrl'])\n",
    "res_df['AUC_pROC'] = AUC_CI[:,1]\n",
    "res_df['AUC_pROC_low'] = AUC_CI[:,0]\n",
    "res_df['AUC_pROC_high'] = AUC_CI[:,2]\n",
    "res_df['protein'] =  ['']+list(boot[0])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df.to_csv(folder+plots+'{}_{}_NumProtein_forward_y{}.csv'.format(endpoint,dataset,k))\n",
    "res_df.to_csv(folder+plots+'{}_{}_NumProtein_forward_noGDF15_y{}.csv'.format(endpoint,dataset,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=[8,5])\n",
    "# fig.add_subplot(1,2,1)\n",
    "\n",
    "plt.plot(AUC_CI[:,1])\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Number of proteins')\n",
    "plt.grid()\n",
    "plt.title('{}-Year Mortality'.format(k+1))\n",
    "\n",
    "# plt.savefig(folder+plots+'{}_{}_NumProtein_forward_AUC_y{}.png'.format(endpoint,dataset,k))\n",
    "plt.savefig(folder+plots+'{}_{}_NumProtein_forward_noGDF15_AUC_y{}.png'.format(endpoint,dataset,k))\n",
    "\n",
    "plt.figure()\n",
    "    # fig.add_subplot(1,2,2)\n",
    "plt.plot(NRI_low[:,0])\n",
    "plt.plot(NRI_middle[:,0])\n",
    "plt.plot(NRI_high[:,0])\n",
    "# plt.plot(IDI)\n",
    "plt.ylabel('NRI')\n",
    "plt.xlabel('Number of proteins')\n",
    "plt.grid()\n",
    "plt.legend(['threshold = 0.3','threshold = 0.5','threshold=0.7'])\n",
    "plt.title('Age+sex+protein')\n",
    "\n",
    "print(AUC_CI[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000 bootstrap testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=k_plot\n",
    "k2=k+1\n",
    "\n",
    "nump = 100 \n",
    "K = [k_plot]\n",
    "NRI_low = np.zeros([nump,5])\n",
    "NRI_middle =  np.zeros([nump,5])\n",
    "NRI_high =  np.zeros([nump,5])\n",
    "IDI =  np.zeros([nump,5])\n",
    "AUC =  np.zeros([nump,5])\n",
    "AUC_CI = []\n",
    "NRI_low_CI = []\n",
    "NRI_middle_CI = []\n",
    "NRI_high_CI = []\n",
    "out_list = []\n",
    "for j,k in enumerate(K):\n",
    "\n",
    "    for i in range(nump):\n",
    "        for l in range(1):\n",
    "#             pred = pd.DataFrame(pred_test_dict['{}_y{}_agesex_forwardp{}_elnet'.format(dataset,k,i)],index=I_test)[0]\n",
    "#             baseline = pd.DataFrame(pred_test_dict['{}_y{}_agesex_forwardp0_elnet'.format(dataset,k)],index=I_test)[0]\n",
    "            \n",
    "            pred = pd.DataFrame(pred_test_dict['{}_y{}_agesex_l1boot1000p{}_l2'.format(dataset,k,i)],index=I_test)[0]\n",
    "            baseline = pd.DataFrame(pred_test_dict['{}_y{}_agesex_l1boot1000p0_l2'.format(dataset,k)],index=I_test)[0]\n",
    "#             pred = pd.DataFrame(pred_test_dict['predy{}_{}_tradprs_boot_forwardp{}_coxl2'.format(k,dataset,i)][0],index=I_test)[0]\n",
    "#             baseline = pd.DataFrame(pred_test_dict['predy{}_{}_tradprs_boot_forwardp0_coxl2'.format(k,dataset)][0],index=I_test)[0]\n",
    "\n",
    "            out = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.3,1])\n",
    "            out_list.append(out)\n",
    "            NRI_low[i,l] = out[4]\n",
    "            NRI_middle[i,l] = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.5,1])[4]\n",
    "            NRI_high[i,l] = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.7,1])[4]\n",
    "            IDI[i,l] = out[3]\n",
    "            AUC[i,l] = out[0]\n",
    "            \n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.3)\n",
    "#             NRI_low_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.5)\n",
    "#             NRI_middle_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.7)\n",
    "#             NRI_high_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "            \n",
    "            AUC_CI.append(R_pROC_AUC(y[k][I_test],pred))\n",
    "AUC_CI = np.array(AUC_CI)\n",
    "# NRI_low_CI = np.array(NRI_low_CI)\n",
    "# NRI_middle_CI = np.array(NRI_middle_CI)\n",
    "# NRI_high_CI = np.array(NRI_high_CI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=[16,5])\n",
    "fig.add_subplot(1,2,1)\n",
    "# plt.plot(Cindex[:,0,0])\n",
    "# plt.plot(AUC[:,0])\n",
    "# plt.plot(AUC_CI[:,1])\n",
    "plt.plot(AUC_CI[:,1])\n",
    "# plt.fill_between(range(AUC_CI.shape[0]),AUC_CI[:,0], AUC_CI[:,2], alpha=0.1)\n",
    "# plt.plot(Cindex[:,0,1])\n",
    "# plt.plot(Cindex[:,0,2])\n",
    "# plt.plot(np.mean(Cindex[:,:,0],axis=1))\n",
    "# plt.plot(np.mean(NRI_low,axis=1))\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Number of proteins')\n",
    "plt.grid()\n",
    "plt.title('Age+sex+protein')\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.plot(NRI_low[:,0])\n",
    "plt.plot(NRI_middle[:,0])\n",
    "plt.plot(NRI_high[:,0])\n",
    "# plt.plot(IDI)\n",
    "plt.ylabel('NRI')\n",
    "plt.xlabel('Number of proteins')\n",
    "plt.grid()\n",
    "plt.legend(['threshold = 0.3','threshold = 0.5','threshold=0.7'])\n",
    "plt.title('Age+sex+protein')\n",
    "\n",
    "plt.savefig(folder+plots+'{}_{}_NumProtein_Lassoboot_y{}.png'.format(endpoint,dataset,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=k_plot\n",
    "# k=9\n",
    "k2=k+1\n",
    "\n",
    "nump = 100 \n",
    "K = [k]\n",
    "NRI_low = np.zeros([nump,5])\n",
    "NRI_middle =  np.zeros([nump,5])\n",
    "NRI_high =  np.zeros([nump,5])\n",
    "IDI =  np.zeros([nump,5])\n",
    "AUC =  np.zeros([nump,5])\n",
    "AUC_CI = []\n",
    "NRI_low_CI = []\n",
    "NRI_middle_CI = []\n",
    "NRI_high_CI = []\n",
    "out_list = []\n",
    "for j,k in enumerate(K):\n",
    "\n",
    "    for i in range(nump):\n",
    "        for l in range(1):\n",
    "            pred = pd.DataFrame(pred_test_dict['{}_y{}_agesex_backward_p{}_l2'.format(dataset,k,i)],index=I_test)[0]\n",
    "            baseline = pd.DataFrame(pred_test_dict['{}_y{}_agesex_backward_p0_l2'.format(dataset,k)],index=I_test)[0]\n",
    "            \n",
    "#             pred = pd.DataFrame(pred_test_dict['{}_y{}_agesexp{}_elnet'.format(dataset,k,i)],index=I_test)[0]\n",
    "#             baseline = pd.DataFrame(pred_test_dict['{}_y{}_agesexp0_elnet'.format(dataset,k)],index=I_test)[0]\n",
    "#             pred = pd.DataFrame(pred_test_dict['predy{}_{}_tradprs_boot_forwardp{}_coxl2'.format(k,dataset,i)][0],index=I_test)[0]\n",
    "#             baseline = pd.DataFrame(pred_test_dict['predy{}_{}_tradprs_boot_forwardp0_coxl2'.format(k,dataset)][0],index=I_test)[0]\n",
    "\n",
    "            out = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.3,1])\n",
    "            out_list.append(out)\n",
    "            NRI_low[i,l] = out[4]\n",
    "            NRI_middle[i,l] = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.5,1])[4]\n",
    "            NRI_high[i,l] = calculate_metrics(pred,baseline,y[k][I_test],bins=[0,0.7,1])[4]\n",
    "            IDI[i,l] = out[3]\n",
    "            AUC[i,l] = out[0]\n",
    "            \n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.3)\n",
    "#             NRI_low_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.5)\n",
    "#             NRI_middle_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "#             NRI = R_NRIbin(y[k][I_test],baseline,pred, 0.7)\n",
    "#             NRI_high_CI.append(np.array(NRI[0].loc['NRI',:]))\n",
    "            \n",
    "            AUC_CI.append(R_pROC_AUC(y[k][I_test],pred))\n",
    "AUC_CI = np.array(AUC_CI)\n",
    "# NRI_low_CI = np.array(NRI_low_CI)\n",
    "# NRI_middle_CI = np.array(NRI_middle_CI)\n",
    "# NRI_high_CI = np.array(NRI_high_CI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=[16,5])\n",
    "fig.add_subplot(1,2,1)\n",
    "# plt.plot(Cindex[:,0,0])\n",
    "# plt.plot(AUC[:,0])\n",
    "# plt.plot(AUC_CI[:,1])\n",
    "plt.plot(AUC_CI[:,1])\n",
    "# plt.fill_between(range(AUC_CI.shape[0]),AUC_CI[:,0], AUC_CI[:,2], alpha=0.1)\n",
    "# plt.plot(Cindex[:,0,1])\n",
    "# plt.plot(Cindex[:,0,2])\n",
    "# plt.plot(np.mean(Cindex[:,:,0],axis=1))\n",
    "# plt.plot(np.mean(NRI_low,axis=1))\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Number of proteins')\n",
    "plt.grid()\n",
    "plt.title('Age+sex+protein')\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.plot(NRI_low[:,0])\n",
    "plt.plot(NRI_middle[:,0])\n",
    "plt.plot(NRI_high[:,0])\n",
    "# plt.plot(IDI)\n",
    "plt.ylabel('NRI')\n",
    "plt.xlabel('Number of proteins')\n",
    "plt.grid()\n",
    "plt.legend(['threshold = 0.3','threshold = 0.5','threshold=0.7'])\n",
    "plt.title('Age+sex+protein')\n",
    "\n",
    "plt.savefig(folder+plots+'{}_{}_NumProtein_backward_y{}.png'.format(endpoint,dataset,k))\n",
    "\n",
    "print(AUC_CI[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test statistics metrics forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(folder+pred_folder + \"{}_{}_forward.pkl\".format(endpoint,dataset),'rb')\n",
    "bootstrap_dict = pickle.load(file)\n",
    "k = 9\n",
    "print(k)\n",
    "print(bootstrap_dict.keys())\n",
    "boot = bootstrap_dict['{}_y{}_asprotein_lr'.format(dataset,k)]\n",
    "boot_df = pd.DataFrame(boot[1])\n",
    "boot_df.set_index(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boot_df.sort_values(1)\n",
    "feat_sorted = list(boot_df.mean(axis=1).sort_values().index)\n",
    "feat_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_list = []\n",
    "metrics_list = []\n",
    "y_train = y[k][I_train]\n",
    "for i in range(0,101):\n",
    "    print(feat_sorted[:i])  \n",
    "\n",
    "    feat = []        \n",
    "    feat.extend(agesex)\n",
    "    feat.extend(feat_sorted[:i])\n",
    "\n",
    "    model = sm.Logit(y_train,sm.add_constant(X_train[feat]))\n",
    "    res = model.fit(disp=0)\n",
    "    metrics_list.append([res.llf, res.llr_pvalue, res.aic,res.bic])\n",
    "    res_list.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(metrics_list)[:,3])\n",
    "plt.xlabel('Number of proteins')\n",
    "plt.ylabel('BIC')\n",
    "plt.scatter(np.argmin(np.array(metrics_list)[:,3]), np.min(np.array(metrics_list)[:,3]))\n",
    "plt.title('Traing set {} year prediction'.format(k+1))\n",
    "plt.savefig(folder+plots+'{}_{}_NumProtein_forward_BIC_y{}.png'.format(endpoint,dataset,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(metrics_list)[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmin(np.array(metrics_list)[:,3]))\n",
    "(feat_sorted[:np.argmin(np.array(metrics_list)[:,3])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_dict.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
