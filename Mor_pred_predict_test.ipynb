{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix, log_loss\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFE, RFECV, SelectPercentile, SelectFpr, SelectFdr, SelectFwe\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif, SelectFdr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "# import lifelines as ll\n",
    "# from lifelines.utils.sklearn_adapter import sklearn_adapter\n",
    "# CoxRegression = sklearn_adapter(ll.CoxPHFitter, event_col = 'event')\n",
    "import sys\n",
    "sys.path.append('/odinn/users/thjodbjorge/Python_functions/')\n",
    "import Predict_functions as pf\n",
    "from Calculate_score import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/odinn/users/thjodbjorge/Proteomics/Mortality2/'\n",
    "feat_folder = 'Features2/'\n",
    "pred_folder = 'Predictions4/'\n",
    "# corr_type = 'sitesampleageqt'\n",
    "corr_type = 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if corr_type == 'qt':\n",
    "    print('Load qt transformed proteins')\n",
    "    proteins = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/protein_data/protein_qt.csv',index_col = 'Barcode2d' )\n",
    "else:\n",
    "    print('Load raw protein values')\n",
    "    raw_data = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/raw_with_info.csv',index_col = 'Barcode2d' )\n",
    "    \n",
    "probe_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probe_info.csv', index_col = 'SeqId')\n",
    "\n",
    "pn_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/pn_info_Mor/pn_info_Mor_event.csv',index_col = 'Barcode2d' )\n",
    "probes_to_skip = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probes_to_skip.txt')['probe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if corr_type == 'pqtl':\n",
    "    pqtl_protein = pd.read_csv('/odinn/users/egilf/pQTL/for_benedikt/pQTL_conditional_04052020.gor', sep='\\t')\n",
    "    # pqtl = pd.read_csv('/odinn/users/steinthora/proteomics/proteomic_project/Data/pQTL_Merged_08052020.csv', sep = '\\t', index_col = 'PN')\n",
    "    pqtl = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/pqtl/pqtl_combined_meanimp.csv',index_col = 'PN')\n",
    "\n",
    "\n",
    "    # In[4]:\n",
    "\n",
    "    pqtl = pd.merge(pn_info['PN'],pqtl,left_on='PN',right_index=True)\n",
    "    pqtl.drop('PN',axis=1,inplace=True)\n",
    "    pro_pqtl = {}\n",
    "    for i in raw_data.iloc[:,16:].columns:\n",
    "        pro_pqtl[i] = list(pqtl_protein[pqtl_protein.SeqId == i[6:].replace('-','_')]['SentinelMarker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoints = ['death']\n",
    "# endpoints = ['death','Cdeath','Gdeath','Ideath','Jdeath','Otherdeath']\n",
    "# event_date = event_date_death\n",
    "time_to_event = pn_info.time_to_death\n",
    "no_event_before = pn_info.no_death_before\n",
    "for endpoint in endpoints:\n",
    "    if endpoint == 'death':\n",
    "        use_event = pn_info.event_death\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Cdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'C')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Gdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'G')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Ideath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'I')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Jdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'J')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Otherdeath':\n",
    "        use_event = pn_info.event_death & (~(pn_info.ICD_group == 'C')&~(pn_info.ICD_group == 'G')&~(pn_info.ICD_group == 'I')&~(pn_info.ICD_group == 'J'))\n",
    "        print(use_event.sum())\n",
    "\n",
    "y = []\n",
    "for i in range(1,19):\n",
    "    y.append(use_event & (time_to_event <= i))\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=10, shuffle=False) \n",
    "I_train_main, I_test_main = train_test_split(pn_info.index, train_size=0.7, random_state = 10)\n",
    "# I_val_main, I_test_main = train_test_split(I_test_main, train_size=0.5, random_state = 10)\n",
    "\n",
    "\n",
    "\n",
    "file = open(folder+\"{}_keep_samples.pkl\".format('Mor'),'rb')\n",
    "keep_samples_dict = pickle.load(file)\n",
    "\n",
    "# print(keep_samples_dict.keys())\n",
    "# keep_samples_keys = ['Old_18105', 'Old_60105', 'Old_6080','Old_18105_C', 'Old_18105_I', 'Old_18105_J', 'Old_18105_G','Old_18105_Other']\n",
    "keep_samples_keys = ['Old_18105']#,'Old_60105']\n",
    "# keep_samples_keys = ['Old_no_comor_18105']\n",
    "# keep_samples_keys = ['Old_18105_Neoplasms','Old_18105_I','Old_18105_J','Old_18105_G','Old_18105_Other']\n",
    "# keep_samples_keys = ['Old_cardio_risk_18105']\n",
    "skip_PC = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in keep_samples_keys:\n",
    "\n",
    "    print(dataset)\n",
    "    keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "    I_train = I_train_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "    I_test = I_test_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "\n",
    "    print('Training set: {}, MI within 15: {}, 10: {}, 5: {}, 2: {}'.format(len(I_train),y[14][I_train].sum(),y[9][I_train].sum(),y[4][I_train].sum(),y[1][I_train].sum()))\n",
    "    print('Test set: {}, MI within 15: {}, 10: {}, 5: {}, 2: {}'.format(len(I_test),y[14][I_test].sum(),y[9][I_test].sum(),y[4][I_test].sum(),y[1][I_test].sum()))\n",
    "\n",
    "        # ### Select data and normalize\n",
    "\n",
    "    if corr_type == 'qt':\n",
    "        X = proteins\n",
    "    else:\n",
    "        X = np.log(raw_data.iloc[:,16:].drop(probes_to_skip,axis=1))\n",
    "\n",
    "    all_protein = X.columns\n",
    "    X['sex'] = pn_info[['sex']].values-1\n",
    "    X['age'] = pn_info[['Age_at_sample_collection_2']].values\n",
    "\n",
    "    X['age2'] = X['age']**2\n",
    "#     X['age3'] = X['age']**3\n",
    "    X['agesex'] = X['age']*X['sex']\n",
    "    X['age2sex'] = X['age2']*X['sex']\n",
    "        \n",
    "    agesex = ['age','sex','agesex','age2','age2sex']\n",
    "       \n",
    "    X['lnage'] = np.log(X['age'])\n",
    "    X['lnage2'] = X['lnage']**2\n",
    "    \n",
    "    X['PAD'] = pn_info['PAD']\n",
    "    no_bmi = (X['PAD'].isna())\n",
    "    no_bmi_ind = X[no_bmi].index\n",
    "    X.loc[I_train.intersection(no_bmi_ind),'PAD'] = X.loc[I_train].PAD.mean()\n",
    "    X.loc[I_test.intersection(no_bmi_ind),'PAD'] = X.loc[I_test].PAD.mean()\n",
    "    \n",
    "    \n",
    "    X['CAD'] = ~pn_info.no_CAD_before\n",
    "    X['MI'] = ~pn_info.no_MI_before\n",
    "    X['PCE'] = ~pn_info.no_PCEend_before\n",
    "    X['Stroke'] = ~pn_info.no_stroke_before\n",
    "    X['cancer'] = pn_info.cancer_margin\n",
    "    X['ApoB'] = X['SeqId.2797-56']\n",
    "    X['Smoker'] = pn_info['Smoker'].astype(int).values\n",
    "    X['diabetes'] = pn_info['T2D'].astype(int).values\n",
    "    X['HTN_treated'] = pn_info[['HTN_treated']].astype(int).values\n",
    "#     X['statin'] = pn_info['statin'].astype(int).values\n",
    "    X['statin'] = pn_info['statin_estimate_unsure'].astype(int).values\n",
    "    X['ApoBstatin']  = X['ApoB']*X['statin']\n",
    "\n",
    "    X['cancer1y']  = pn_info['cancer1y']\n",
    "    X['cancer5y']  = pn_info['cancer5y']\n",
    "\n",
    "    X['GDF15'] = X['SeqId.4374-45'].copy()\n",
    "    X['GDF152'] = X['GDF15']**2\n",
    "    X['GDF15age']  = X['GDF15']*X['age']\n",
    "    X['GDF15sex']  = X['GDF15']*X['sex']\n",
    "    \n",
    "    X['bmi'] = pn_info['bmi']\n",
    "\n",
    "    no_bmi = (X['bmi'].isna())\n",
    "    no_bmi_ind = X[no_bmi].index\n",
    "#     X.loc[no_bmi_ind,'bmi'] = X.loc[I_train].bmi.mean()\n",
    "    X.loc[I_train.intersection(no_bmi_ind),'bmi'] = X.loc[I_train].bmi.mean()       \n",
    "    X.loc[I_test.intersection(no_bmi_ind),'bmi'] = X.loc[I_test].bmi.mean()   \n",
    "    \n",
    "    X['bmi2'] = X['bmi']*X['bmi']\n",
    "    \n",
    "    X['Platelets'] = pn_info['Platelets']\n",
    "    no_p = (X['Platelets'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Platelets'] = X.loc[I_train].Platelets.mean()\n",
    "    X.loc[I_test.intersection(no_p_ind),'Platelets'] = X.loc[I_test].Platelets.mean()\n",
    "    X['Platelets2'] = X['Platelets']*X['Platelets']\n",
    "    \n",
    "    X['Creatinine'] = pn_info['Creatinine']\n",
    "    no_p = (X['Creatinine'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Creatinine'] = X.loc[I_train].Creatinine.mean()\n",
    "    X.loc[I_test.intersection(no_p_ind),'Creatinine'] = X.loc[I_test].Creatinine.mean()\n",
    "    \n",
    "    X['Triglycerides'] = pn_info['Triglycerides']\n",
    "    no_p = (X['Triglycerides'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Triglycerides'] = X.loc[I_train].Triglycerides.mean()    \n",
    "    X.loc[I_test.intersection(no_p_ind),'Triglycerides'] = X.loc[I_test].Triglycerides.mean()   \n",
    "    \n",
    "\n",
    "    X['bmiage'] = X['bmi']*X['age']\n",
    "    X['bmisex'] = X['bmi']*X['sex']\n",
    "    X['bmi2age'] = X['bmi2']*X['age']\n",
    "    X['bmi2sex'] = X['bmi2']*X['sex']\n",
    "    X['PADage'] = X['PAD']*X['age']\n",
    "    X['PADsex'] = X['PAD']*X['sex']\n",
    "    \n",
    "    X['ApoBage']  = X['ApoB']*X['age']\n",
    "    X['Smokerage'] = X['Smoker']*X['age']\n",
    "    X['diabetesage'] = X['diabetes']*X['age'] \n",
    "    X['statinage'] = X['statin']*X['age']\n",
    "    X['CADage'] = X['CAD']*X['age']\n",
    "    X['MIage'] = X['MI'] * X['age']\n",
    "    X['HTN_treatedage'] =  X['age']*X['HTN_treated']    \n",
    "    X['cancerage'] = X['age']*X['cancer']\n",
    "    \n",
    "    X['Plateletsage'] = X['Platelets']*X['age']\n",
    "    X['Creatinineage'] = X['Creatinine']*X['age']\n",
    "    X['Triglyceridesage'] = X['Triglycerides']*X['age']    \n",
    "    X['Platelets2age'] = X['Platelets2']*X['age']\n",
    "    \n",
    "    X['cancer1yage'] = X['cancer1y']*X['age'] \n",
    "    X['cancer5yage'] = X['cancer5y']*X['age']     \n",
    "    \n",
    "    X['ApoBsex']  = X['ApoB']*X['sex']\n",
    "    X['Smokersex'] = X['Smoker']*X['sex']\n",
    "    X['diabetessex'] = X['diabetes']*X['sex'] \n",
    "    X['statinsex'] = X['statin']*X['sex']\n",
    "    X['CADsex'] = X['CAD']*X['sex']\n",
    "    X['MIsex'] = X['MI'] * X['sex']\n",
    "    X['HTN_treatedsex'] =  X['sex']*X['HTN_treated']   \n",
    "    X['cancersex'] = X['sex']*X['cancer']\n",
    "    \n",
    "    X['Plateletssex'] = X['Platelets']*X['sex']\n",
    "    X['Creatininesex'] = X['Creatinine']*X['sex']\n",
    "    X['Triglyceridessex'] = X['Triglycerides']*X['sex']        \n",
    "    \n",
    "    X = X.join(pd.get_dummies(pn_info['agebin'],drop_first = True,prefix='age'))\n",
    "    X['ageage2'] = X['age']*X['age_2.0']\n",
    "    X['ageage3'] = X['age']*X['age_3.0']\n",
    "    X['ageage4'] = X['age']*X['age_4.0']\n",
    "    \n",
    "    agebins = ['age_2.0','age_3.0','age_4.0', 'ageage2','ageage3','ageage4']\n",
    "    agebinssex = [s+'sex' for s in agebins]\n",
    "    X[agebinssex] = (X[agebins].transpose()*X['sex']).transpose()    \n",
    "    \n",
    "    batch_var = pd.get_dummies(pn_info['batch'],drop_first = True).columns\n",
    "    X[batch_var] = pd.get_dummies(pn_info['batch'],drop_first = True)\n",
    "    \n",
    "    PRS = ['nonHDL_prs', 'HT_prs', 'CAD_prs', 'Cancer_prs', 'Stroke2_prs', 'alz_Jansen',\n",
    "       'pgc_adhd_2017', 'PD_Nalls_2018', 'edu_160125', 'dep_2018', 'bpd_2018',\n",
    "       'giant_bmi', 'schizo_clozuk', 'iq_2018', 'ipsych_pgc_aut_2017',\n",
    "       'pgc_Anorexia_2019']\n",
    "    X[PRS] = pn_info[PRS]\n",
    "    \n",
    "    X['site'] = (pn_info['site'] == 'DC').astype(int)\n",
    "    X['Sample_age'] = pn_info['Sample_age']\n",
    "    \n",
    "    try: \n",
    "        print('Load age dictonary')\n",
    "        file = open(folder+pred_folder+\"age_predict.pkl\",'rb')\n",
    "        age_dict = pickle.load(file)\n",
    "        file.close()\n",
    "        PAD2 = age_dict['{}_sexprotein_lasso'.format(dataset)][4]-X.age\n",
    "        X['PAD2'] = PAD2\n",
    "    except:\n",
    "        print('No file to load')\n",
    "    if corr_type == 'pqtl':\n",
    "        X =X.merge(pqtl,how = 'left', right_index=True, left_index=True)\n",
    "    \n",
    "    X_train = X.loc[I_train]\n",
    "    X_test = X.loc[I_test]\n",
    "    \n",
    "    if corr_type == 'pqtl':\n",
    "        ### Correct for pqtls\n",
    "        for m in pqtl.columns:\n",
    "            no_p = (X[m].isna());# print(no_p.sum())\n",
    "            no_p_ind = X[no_p].index\n",
    "            X_train.loc[I_train.intersection(no_p_ind),m] = X_train[m].mean()\n",
    "            X_test.loc[I_test.intersection(no_p_ind),m] = X_test[m].mean()\n",
    "\n",
    "        for p in all_protein:    \n",
    "            pqtl_model = sm.OLS(X_train[p],sm.add_constant(X_train[pro_pqtl[p]])).fit()\n",
    "            corr_train = pqtl_model.predict(sm.add_constant(X_train[pro_pqtl[p]]))\n",
    "            corr_test = pqtl_model.predict(sm.add_constant(X_test[pro_pqtl[p]]))\n",
    "        #     corr_train.columns = all_protein\n",
    "            X_train[p] = X_train[p] - corr_train\n",
    "            X_test[p] = X_test[p] - corr_test\n",
    "            \n",
    "    if corr_type == 'sitesampleage':\n",
    "        print('Correct proteins fro site and sample age')\n",
    "        for p in all_protein:    \n",
    "            corr_model = sm.OLS(X_train[p],sm.add_constant(X_train[['site','Sample_age']])).fit()\n",
    "            corr_train = corr_model.predict(sm.add_constant(X_train[['site','Sample_age']]))\n",
    "            corr_test = corr_model.predict(sm.add_constant(X_test[['site','Sample_age']]))\n",
    "        #     corr_train.columns = all_protein\n",
    "            X_train[p] = X_train[p] - corr_train\n",
    "            X_test[p] = X_test[p] - corr_test\n",
    "        print('Correction done')     \n",
    "        \n",
    "        \n",
    "    if corr_type == 'sitesampleageqt':\n",
    "        print('Correct proteins for site and sample age')\n",
    "        for p in all_protein:    \n",
    "            corr_model = sm.OLS(X_train[p],sm.add_constant(X_train[['site','Sample_age']])).fit()\n",
    "            corr_train = corr_model.predict(sm.add_constant(X_train[['site','Sample_age']]))\n",
    "            corr_test = corr_model.predict(sm.add_constant(X_test[['site','Sample_age']]))\n",
    "        #     corr_train.columns = all_protein\n",
    "            X_train[p] = X_train[p] - corr_train\n",
    "            X_test[p] = X_test[p] - corr_test\n",
    "        print('Normalize proteins')    \n",
    "        transformer = QuantileTransformer(n_quantiles=50000, output_distribution = 'normal',random_state=10)\n",
    "        transformer.fit(X_train[all_protein])\n",
    "        X_train[all_protein] = transformer.transform(X_train[all_protein])\n",
    "        X_test[all_protein] = transformer.transform(X_test[all_protein]) \n",
    "        \n",
    "    if corr_type == 'batch':\n",
    "        for p in all_protein:    \n",
    "            corr_model = sm.OLS(X_train[p],sm.add_constant(X_train[batch_var])).fit()\n",
    "            corr_train = corr_model.predict(sm.add_constant(X_train[batch_var]))\n",
    "            corr_test = corr_model.predict(sm.add_constant(X_test[batch_var]))\n",
    "        #     corr_train.columns = all_protein\n",
    "            X_train[p] = X_train[p] - corr_train\n",
    "            X_test[p] = X_test[p] - corr_test           \n",
    "        \n",
    "    \n",
    "    if corr_type == 'PCA':\n",
    "        pca1 = PCA(skip_PC)\n",
    "        x_pca1 = pca1.fit_transform(X_train[all_protein])\n",
    "        x_1 = pca1.inverse_transform(x_pca1)\n",
    "        X_train[all_protein] = X_train[all_protein] - x_1\n",
    "\n",
    "        x_pca1 = pca1.transform(X_test[all_protein])\n",
    "        x_1 = pca1.inverse_transform(x_pca1)\n",
    "        X_test[all_protein] = X_test[all_protein] - x_1\n",
    "    \n",
    "    \n",
    "    train_mean = X_train.mean()\n",
    "    train_std = X_train.std()\n",
    "\n",
    "    X_train = (X_train-train_mean)/train_std\n",
    "    X_test = (X_test-train_mean)/train_std\n",
    "\n",
    "        ## For survival analysis    \n",
    "    X_train['event'] = use_event[I_train]\n",
    "    X_test['event'] = use_event[I_test]\n",
    "\n",
    "    tte_train = time_to_event[I_train]\n",
    "    tte_test = time_to_event[I_test]\n",
    "\n",
    "    ysurv_train = pd.DataFrame()\n",
    "    ysurv_train['event'] = use_event[I_train]\n",
    "    ysurv_train['time_to_event'] = time_to_event[I_train]\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_type)\n",
    "if corr_type == 'qt':\n",
    "    print('qt')\n",
    "elif corr_type == 'pqtl':\n",
    "    print(pqtl)\n",
    "elif corr_type == 'sitesampleage':\n",
    "    print('correct for site and sample age')\n",
    "elif corr_type == 'sitesampleageqt':\n",
    "    print('correct for site and sample age and normalize on training data')\n",
    "elif corr_type == 'batch':\n",
    "    print('correct for batch')\n",
    "else:\n",
    "    print('Normal version(just log transformed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression main models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# K = [4, 9]\n",
    "K = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "try: \n",
    "    file = open(folder+pred_folder+\"{}_{}_predict.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    pred_dict = {}\n",
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder + \"{}_{}_test_prediction.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_test_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_test_dict = {}    \n",
    "\n",
    "### Run all predictions \n",
    "    \n",
    "# model_keys =pred_dict.keys()\n",
    "# # new_keys = []\n",
    "# # for key in model_keys:\n",
    "# #     if 'baseline2' in key:\n",
    "# #         new_keys.append(key)\n",
    "# # model_keys = new_keys\n",
    "# for model_key in model_keys:\n",
    "#     model = pred_dict[model_key][0]\n",
    "#     feat = pred_dict[model_key][3]\n",
    "# #     model = pred_dict['{}_proteinL1_y{}'.format(dataset,k)][0]\n",
    "#     pred_test = model.predict_proba(X_test[feat])[:,1]\n",
    "# #             pred_test =  pf.predictions_surv(model,feat,X_test,k)\n",
    "\n",
    "#     pred_test_dict[model_key] = pred_test\n",
    "\n",
    "#### Run selected predicitons\n",
    "\n",
    "for k in K:\n",
    "#     model_keys = ['{}_y{}_baselineminusMI_lr'.format(dataset,k)]   \n",
    "#     model_keys = ['{}_y{}_baselineplusPCE_lr'.format(dataset,k)]   \n",
    "#     model_keys = ['{}_y{}_agesexproteinqt_l1'.format(dataset,k),'{}_y{}_agesexGDF15qt_lr'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_agesexproteincorr_l1'.format(dataset,k),'{}_y{}_agesexGDF15corr_lr'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_agesexproteincorrqt_l1'.format(dataset,k),'{}_y{}_agesexGDF15corrqt_lr'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_agesexproteinbatchcorr_l1'.format(dataset,k),'{}_y{}_agesexGDF15bathccorr_lr'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_agesexproteinnoGDF15_l1'.format(dataset,k),'{}_y{}_proteinnoGDF15_l1'.format(dataset,k),'{}_y{}_baselineproteinnoGDF15_l1'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_baseline2elife_lr'.format(dataset,k),'{}_y{}_baseline2elife_l2'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_agesexprotein3_l1'.format(dataset,k),'{}_y{}_agesexprotein7_l1'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_lifestyle_lr'.format(dataset,k),'{}_y{}_lifestyleGDF15_lr'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_agesexPLAUR_lr'.format(dataset,k),'{}_y{}_baseline2PLAUR_lr'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_GDF15_lr'.format(dataset,k)]\n",
    "#     model_keys = ['{}_y{}_agesexstepBIC_l2'.format(dataset,k)]   \n",
    "#             model_keys = ['{}_y{}_agesexGDF15ultra_lr'.format(dataset,k)]   \n",
    "#             model_keys = ['{}_y{}_baselineGDF15PAD_lr'.format(dataset,k)]   \n",
    "    model_keys = ['{}_y{}_baseline2PAD2_lr'.format(dataset,k)]     \n",
    "#             model_keys = ['{}_y{}_agesexPAD_lr'.format(dataset,k)]       \n",
    "#             model_keys = ['{}_y{}_protein_l1'.format(dataset,k)]\n",
    "#             model_keys = ['{}_y{}_agesexproteinpqtl_l1'.format(dataset,k)]\n",
    "#             model_keys = ['{}_y{}_baselineproteinPC{}_l1'.format(dataset,k,skip_PC)]\n",
    "#             model_keys = ['{}_y{}_agesexproteinPC{}_l1'.format(dataset,k,skip_PC)]\n",
    "    for model_key in model_keys:\n",
    "        model = pred_dict[model_key][0]\n",
    "        feat = pred_dict[model_key][3]\n",
    "#     model = pred_dict['{}_proteinL1_y{}'.format(dataset,k)][0]\n",
    "        pred_test = model.predict_proba(X_test[feat])[:,1]\n",
    "#             pred_test =  pf.predictions_surv(model,feat,X_test,k)\n",
    "\n",
    "        pred_test_dict[model_key] = pred_test\n",
    "\n",
    "###################\n",
    "#     f = open(folder+pred_folder+\"{}_{}_test_prediction.pkl\".format(endpoint,dataset),\"wb\")\n",
    "#     pickle.dump(pred_test_dict,f)\n",
    "#     f.close()\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# f = open(folder+pred_folder+\"{}_{}_test_prediction.pkl\".format(endpoint,dataset),\"wb\")\n",
    "# pickle.dump(pred_test_dict,f)\n",
    "# f.close()\n",
    "# print('Done')\n",
    "\n",
    "pred_test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(pred_dict['{}_y{}_baseline2hopro_lr'.format(dataset,9)][0].coef_[0],pred_dict['{}_y{}_baseline2hopro_lr'.format(dataset,9)][3])\n",
    "# pred_dict['{}_y{}_baseline2hopro_lr'.format(dataset,9)][3],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cox models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder+\"{}_{}_predict_cox.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    pred_dict = {}\n",
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder + \"{}_{}_test_prediction.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_test_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_test_dict = {}    \n",
    "\n",
    "\n",
    "K =[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "for k in K:\n",
    "\n",
    "#     model_key = '{}_boruta_y9_coxl2'.format(dataset)\n",
    "    model_keys = pred_dict.keys()\n",
    "    print(model_keys)\n",
    "#     model_keys = ['{}_y{}_agesexstepBIC_l2'.format(dataset,k)]   \n",
    "    for model_key in model_keys:\n",
    "        model = pred_dict[model_key][0]\n",
    "        feat = pred_dict[model_key][3]\n",
    "\n",
    "        pred_test =  pf.predictions_surv(model,feat,X_test,k)\n",
    "\n",
    "        pred_test_dict['predy{}_'.format(k)+ model_key] = np.array(pred_test[0])\n",
    "\n",
    "#         f = open(folder+pred_folder+\"{}_{}_test_prediction.pkl\".format(endpoint,dataset),\"wb\")\n",
    "#         pickle.dump(pred_test_dict,f)\n",
    "#         f.close()\n",
    "        print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(folder+pred_folder+\"{}_{}_test_prediction.pkl\".format(endpoint,dataset),\"wb\")\n",
    "# pickle.dump(pred_test_dict,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# K = [4, 9]\n",
    "# K = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "K=[0]\n",
    "try: \n",
    "    file = open(folder+pred_folder+\"{}_{}_predict_single_protein.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_dict = pickle.load(file)\n",
    "except:\n",
    "    pred_dict = {}\n",
    "\n",
    "try: \n",
    "    file = open(folder+pred_folder + \"{}_{}_test_prediction_single_protein.pkl\".format(endpoint,dataset),'rb')\n",
    "    pred_test_dict = pickle.load(file)\n",
    "except:\n",
    "    print('No test predictions')\n",
    "    pred_test_dict = {}    \n",
    "print(pred_dict.keys())\n",
    "print(\"\")\n",
    "print(pred_test_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k in K:\n",
    "\n",
    "model_keys = pred_dict.keys()\n",
    "for model_key in model_keys:\n",
    "    model = pred_dict[model_key][0]\n",
    "    feat = pred_dict[model_key][3]\n",
    "#     model = pred_dict['{}_proteinL1_y{}'.format(dataset,k)][0]\n",
    "    pred_test = model.predict_proba(X_test[feat])[:,1]\n",
    "#             pred_test =  pf.predictions_surv(model,feat,X_test,k)\n",
    "\n",
    "    pred_test_dict[model_key] = pred_test\n",
    "\n",
    "f = open(folder+pred_folder+\"{}_{}_test_prediction_single_protein.pkl\".format(endpoint,dataset),\"wb\")\n",
    "pickle.dump(pred_test_dict,f)\n",
    "f.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
