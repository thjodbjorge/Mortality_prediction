{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix, log_loss\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFE, RFECV, SelectPercentile, SelectFpr, SelectFdr, SelectFwe\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "import lifelines as ll\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('/odinn/users/thjodbjorge/Python_functions/')\n",
    "import Predict_functions as pf\n",
    "from Feature_selection import stepwise_selection\n",
    "from Calculate_score import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/raw_with_info.csv',index_col = 'Barcode2d' )\n",
    "probe_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probe_info.csv', index_col = 'SeqId')\n",
    "\n",
    "pn_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/pn_info_Mor/pn_info_Mor_event.csv',index_col = 'Barcode2d' )\n",
    "probes_to_skip = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probes_to_skip.txt')['probe']\n",
    "\n",
    "\n",
    "folder = '/odinn/users/thjodbjorge/Proteomics/Mortality2/'\n",
    "org_folder = 'Traditional_risk_factors/'\n",
    "pred_folder = 'Traditional_risk_factors_20210317/'\n",
    "feat_folder = 'Features2/'\n",
    "\n",
    "endpoints = ['death']\n",
    "# endpoints = ['death','Cdeath','Gdeath','Ideath','Jdeath','Otherdeath']\n",
    "# event_date = event_date_death\n",
    "time_to_event = pn_info.time_to_death\n",
    "no_event_before = pn_info.no_death_before\n",
    "for endpoint in endpoints:\n",
    "    if endpoint == 'death':\n",
    "        use_event = pn_info.event_death\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Cdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'C')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Gdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'G')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Ideath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'I')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Jdeath':\n",
    "        use_event = pn_info.event_death & (pn_info.ICD_group == 'J')\n",
    "        print(use_event.sum())\n",
    "    elif endpoint == 'Otherdeath':\n",
    "        use_event = pn_info.event_death & (~(pn_info.ICD_group == 'C')&~(pn_info.ICD_group == 'G')&~(pn_info.ICD_group == 'I')&~(pn_info.ICD_group == 'J'))\n",
    "        print(use_event.sum())\n",
    "\n",
    "\n",
    "y = []\n",
    "for i in range(1,19):\n",
    "    y.append(use_event & (time_to_event <= i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_df = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/qt_pheno_data.csv')\n",
    "# pn_df['Time_of_plasma_collection_2'] = pd.to_datetime(pn_df.Time_of_plasma_collection_2)\n",
    "pn_df.drop('Time_of_plasma_collection_2',inplace=True,axis=1)\n",
    "qt_col = pn_df.columns\n",
    "w1y_qt_col = qt_col[['w1y' in c for c in qt_col]]\n",
    "# Maybe I should normalize all of this because I know nothing about these variables\n",
    "index = pn_info.index\n",
    "pn_info = pn_info.merge(pn_df, how = 'left', left_on = 'PN', right_on = 'PN',suffixes = [None,'_y'])\n",
    "pn_info.index = index\n",
    "\n",
    "extra_feat = ['Stroke','Asthma','HDL','TC','SBP']\n",
    "extra_feat2 = ['Asthma','HDL','TC','SBP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=10, shuffle=False) \n",
    "I_train_main, I_test_main = train_test_split(pn_info.index, train_size=0.7, random_state = 10)\n",
    "I_train_main = pn_info.index\n",
    "# I_val_main, I_test_main = train_test_split(I_test_main, train_size=0.5, random_state = 10)\n",
    "\n",
    "\n",
    "\n",
    "file = open(folder+\"{}_keep_samples.pkl\".format('Mor'),'rb')\n",
    "keep_samples_dict = pickle.load(file)\n",
    "\n",
    "# print(keep_samples_dict.keys())\n",
    "# keep_samples_keys = ['Old_18105', 'Old_60105', 'Old_6080','Old_18105_C', 'Old_18105_I', 'Old_18105_J', 'Old_18105_G','Old_18105_Other']\n",
    "# keep_samples_keys = ['Old_women_18105']\n",
    "keep_samples_keys = ['Old_18105']\n",
    "# K = [9]\n",
    "# K = [4]\n",
    "# K =[14]\n",
    "k =4\n",
    "for dataset in keep_samples_keys:\n",
    "    print(dataset)\n",
    "    keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "    I_train = I_train_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "    I_test = I_test_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "\n",
    "    print('Training set: {}, MI within 15: {}, 10: {}, 5: {}, 2: {}'.format(len(I_train),y[14][I_train].sum(),y[9][I_train].sum(),y[4][I_train].sum(),y[1][I_train].sum()))\n",
    "    print('Test set: {}, MI within 15: {}, 10: {}, 5: {}, 2: {}'.format(len(I_test),y[14][I_test].sum(),y[9][I_test].sum(),y[4][I_test].sum(),y[1][I_test].sum()))\n",
    "\n",
    "        # ### Select data and normalize\n",
    "\n",
    "#     X = np.log(raw_data.iloc[:,16:].drop(probes_to_skip,axis=1))\n",
    "\n",
    "#     all_protein = X.columns\n",
    "    X = pd.DataFrame(index=pn_info.index)\n",
    "    X['sex'] = pn_info[['sex']].values-1\n",
    "    X['age'] = pn_info[['Age_at_sample_collection_2']].values\n",
    "\n",
    "    X['age2'] = X['age']**2\n",
    "#     X['age3'] = X['age']**3\n",
    "    X['agesex'] = X['age']*X['sex']\n",
    "    X['age2sex'] = X['age2']*X['sex']\n",
    "        \n",
    "    agesex = ['age','sex','agesex','age2','age2sex']\n",
    "       \n",
    "    X['lnage'] = np.log(X['age'])\n",
    "    X['lnage2'] = X['lnage']**2\n",
    "    \n",
    "    X['CABG_PCI'] = ~pn_info.no_CABG_PCI_before\n",
    "    X['CAD'] = ~pn_info.no_CAD_before\n",
    "    X['MI'] = ~pn_info.no_MI_before\n",
    "    X['PCE'] = ~pn_info.no_PCEend_before\n",
    "    X['Stroke'] = ~pn_info.no_stroke_before\n",
    "    X['Asthma'] = pn_info.Asthma\n",
    "    X['cancer'] = pn_info.cancer\n",
    "    X['Stroke'] = ~pn_info.no_stroke_before\n",
    "    \n",
    "    X['HDL'] = pn_info.HDL\n",
    "    X['TC'] = pn_info.TC\n",
    "    X['SBP'] = pn_info.SBP\n",
    "    \n",
    "    X['ApoB'] = np.log(pn_info['ApoB'])\n",
    "    X['GDF15'] = np.log(pn_info['GDF15'])\n",
    "    X['Smoker'] = pn_info['Smoker'].astype(int).values\n",
    "    X['diabetes'] = pn_info['T2D'].astype(int).values\n",
    "    X['HTN_treated'] = pn_info[['HTN_treated']].astype(int).values\n",
    "\n",
    "#     X['statin'] = pn_info['statin'].astype(int).values\n",
    "    X['statin'] = pn_info['statin_estimate_unsure'].astype(int).values\n",
    " \n",
    "    X['bmi'] = pn_info['bmi']\n",
    "\n",
    "    no_bmi = (X['bmi'].isna()); print(no_bmi.sum())\n",
    "    no_bmi_ind = X[no_bmi].index\n",
    "    X.loc[I_train.intersection(no_bmi_ind),'bmi'] = X.loc[I_train].bmi.mean()\n",
    "    X['bmi2'] = X['bmi']*X['bmi']\n",
    "    \n",
    "    X['Platelets'] = pn_info['Platelets']\n",
    "    no_p = (X['Platelets'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Platelets'] = X.loc[I_train].Platelets.mean()\n",
    "    X['Platelets2'] = X['Platelets']*X['Platelets']\n",
    "    \n",
    "    X['Creatinine'] = pn_info['Creatinine']\n",
    "    no_p = (X['Creatinine'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Creatinine'] = X.loc[I_train].Creatinine.mean()\n",
    "    \n",
    "    X['Triglycerides'] = pn_info['Triglycerides']\n",
    "    no_p = (X['Triglycerides'].isna()); print(no_p.sum())\n",
    "    no_p_ind = X[no_p].index\n",
    "    X.loc[I_train.intersection(no_p_ind),'Triglycerides'] = X.loc[I_train].Triglycerides.mean()\n",
    "    \n",
    "    \n",
    "\n",
    "    X['bmiage'] = X['bmi']*X['age']\n",
    "    X['bmisex'] = X['bmi']*X['sex']\n",
    "    X['bmi2age'] = X['bmi2']*X['age']\n",
    "    X['bmi2sex'] = X['bmi2']*X['sex']\n",
    "    X['ApoBage']  = X['ApoB']*X['age']\n",
    "    X['Smokerage'] = X['Smoker']*X['age']\n",
    "    X['diabetesage'] = X['diabetes']*X['age'] \n",
    "    X['statinage'] = X['statin']*X['age']\n",
    "    X['CADage'] = X['CAD']*X['age']\n",
    "    X['MIage'] = X['MI'] * X['age']\n",
    "    X['HTN_treatedage'] =  X['age']*X['HTN_treated']    \n",
    "    X['cancerage'] = X['age']*X['cancer']\n",
    "    \n",
    "    X['Plateletsage'] = X['Platelets']*X['age']\n",
    "    X['Creatinineage'] = X['Creatinine']*X['age']\n",
    "    X['Triglyceridesage'] = X['Triglycerides']*X['age']\n",
    "    X['Platelets2age'] = X['Platelets2']*X['age']\n",
    "    \n",
    "    X['ApoBsex']  = X['ApoB']*X['sex']\n",
    "    X['Smokersex'] = X['Smoker']*X['sex']\n",
    "    X['diabetessex'] = X['diabetes']*X['sex'] \n",
    "    X['statinsex'] = X['statin']*X['sex']\n",
    "    X['CADsex'] = X['CAD']*X['sex']\n",
    "    X['MIsex'] = X['MI'] * X['sex']\n",
    "    X['HTN_treatedsex'] =  X['sex']*X['HTN_treated']    \n",
    "    X['cancersex'] = X['sex']*X['cancer']\n",
    "    \n",
    "    X['Plateletssex'] = X['Platelets']*X['sex']\n",
    "    X['Creatininesex'] = X['Creatinine']*X['sex']\n",
    "    X['Triglyceridessex'] = X['Triglycerides']*X['sex']  \n",
    "    X['Platelets2sex'] = X['Platelets2']*X['sex']\n",
    "    \n",
    "    X['ApoBstatin']  = X['ApoB']*X['statin']\n",
    "    \n",
    "    X = X.join(pd.get_dummies(pn_info['agebin'],drop_first = True,prefix='age'))\n",
    "    X['ageage2'] = X['age']*X['age_2.0']\n",
    "    X['ageage3'] = X['age']*X['age_3.0']\n",
    "    X['ageage4'] = X['age']*X['age_4.0']\n",
    "    \n",
    "    agebins = ['age_2.0','age_3.0','age_4.0', 'ageage2','ageage3','ageage4']\n",
    "    agebins60 = ['age_4.0','ageage4']\n",
    "    agebins60sex = ['age_4.0sex','ageage4sex']\n",
    "    agebinssex = [s+'sex' for s in agebins]\n",
    "    X[agebinssex] = (X[agebins].transpose()*X['sex']).transpose()    \n",
    "        \n",
    "    \n",
    "    PRS = ['nonHDL_prs', 'HT_prs', 'CAD_prs', 'Cancer_prs', 'Stroke2_prs', 'alz_Jansen',\n",
    "       'pgc_adhd_2017', 'PD_Nalls_2018', 'edu_160125', 'dep_2018', 'bpd_2018',\n",
    "       'giant_bmi', 'schizo_clozuk', 'iq_2018', 'ipsych_pgc_aut_2017',\n",
    "       'pgc_Anorexia_2019']\n",
    "    X[PRS] = pn_info[PRS]\n",
    "    X[qt_col] = pn_info[qt_col]\n",
    "    \n",
    "#     for c in qt_col[1:100]: \n",
    "#         X[c+'2'] = X[c]**2\n",
    "#         X[c+'age'] = X[c]*X['age']\n",
    "#         X[c+'sex'] = X[c]*X['sex']\n",
    "\n",
    "    for c in extra_feat: \n",
    "        X[c+'2'] = X[c]**2\n",
    "        X[c+'age'] = X[c]*X['age']\n",
    "        X[c+'sex'] = X[c]*X['sex']\n",
    "    \n",
    "    trad = ['ApoB','Smoker','diabetes','HTN_treated','statin','CAD','MI','bmi','cancer']\n",
    "    tradage = ['ApoBage','Smokerage','diabetesage','CADage','MIage','HTN_treatedage','bmiage','statinage','cancerage']\n",
    "    tradsex = ['ApoBsex','Smokersex','diabetessex','CADsex','MIsex','HTN_treatedsex','bmisex','statinsex','cancersex']\n",
    "    \n",
    "    tradcoxR = ['Smoker','Smokersex','diabetes','diabetesage','HTN_treated','HTN_treatedage','MI','MIage','CAD','bmi','bmiage','statin','statinage']\n",
    "    tradblood = ['Platelets','Platelets2','Creatinine','Triglycerides']\n",
    "    tradbloodextra = ['Plateletsage','Creatinineage','Triglyceridesage','Platelets2age','Plateletssex','Creatininesex','Triglyceridessex','Platelets2sex']\n",
    "\n",
    "    tradextralog = ['Smokersex','diabetessex','CADsex','CADage','MIage','HTN_treatedage','bmiage','statinage','bmi2','bmi2age','ApoBstatin','cancerage']  \n",
    "    \n",
    "    org_baseline = trad+tradextralog\n",
    "    new_baseline = ['ApoB','Smoker','diabetes','HTN_treated','statin','CAD','MI','bmi','bmi2','Stroke','Smokersex',\n",
    "             'diabetessex','CADsex','CADage','MIage','HTN_treatedage','bmiage','statinage','bmi2age','ApoBstatin',\n",
    "            'cancer','cancerage','cancersex']\n",
    "    \n",
    "    X_train = X.loc[I_train]\n",
    "    X_test = X.loc[I_test]\n",
    "\n",
    "    train_mean = X_train.mean()\n",
    "    train_std = X_train.std()\n",
    "\n",
    "    X_train = (X_train-train_mean)/train_std\n",
    "    X_test = (X_test-train_mean)/train_std\n",
    "\n",
    "        ## For survival analysis    \n",
    "    X_train['event'] = use_event[I_train]\n",
    "    X_test['event'] = use_event[I_test]\n",
    "   \n",
    "    X_train['time_to_event'] =  time_to_event[I_train]\n",
    "    X_test['time_to_event'] = time_to_event[I_test]\n",
    "    \n",
    "    batch_var = pd.get_dummies(pn_info.loc[I_train,'batch'],drop_first = True).columns\n",
    "    X_train[batch_var] = pd.get_dummies(pn_info.loc[I_train,'batch'],drop_first = True)\n",
    "\n",
    "\n",
    "    y_train = y[k][I_train]\n",
    "    y_test = y[k][I_test]\n",
    "\n",
    "#         ycsurv_train = pd.DataFrame()\n",
    "#         ycsurv_train['event'] = y_train\n",
    "#         ycsurv_train['time_to_event'] = np.where(tte_train<= (k+1),tte_train,k+1)\n",
    "\n",
    "    X_train['y'] = y_train\n",
    "    X_test['y'] = y_test\n",
    "\n",
    "    try:\n",
    "\n",
    "        file = open(folder+feat_folder+\"{}_{}_features.pkl\".format(endpoint,dataset),'rb')\n",
    "        features_dict = pickle.load(file)           \n",
    "\n",
    "        boruta = sorted(features_dict['{}_boruta_y{}'.format(dataset,k)])\n",
    "        print('features_loaded')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('No features')\n",
    "\n",
    "    try: \n",
    "        file = open(folder+pred_folder+\"{}_{}_predict_trad_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "        pred_dict_cv = pickle.load(file)\n",
    "        \n",
    "#         file = open(folder+pred_folder+\"{}_{}_predict_trad_2_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "#         pred_dict_cv_2 = pickle.load(file)\n",
    "        \n",
    "#         file = open(folder+pred_folder+\"{}_{}_predict_trad_cv_3.pkl\".format(endpoint,dataset),'rb')\n",
    "#         pred_dict_cv_3 = pickle.load(file)\n",
    "        \n",
    "#         pred_dict_cv = {**pred_dict_cv, **pred_dict_cv_2, **pred_dict_cv_3}  \n",
    "    except:\n",
    "        pred_dict_cv = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_cv.keys()\n",
    "# pred_dict_cv_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=4\n",
    "# y_train = y[k][I_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = ['age','sex','agesex','age2','age2sex']\n",
    "# feat.extend(agebins)\n",
    "# feat.extend(agebins60)\n",
    "logit = sm.Logit(y_train, sm.add_constant(X_train[feat])).fit()\n",
    "logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0 \n",
    "sign_count = 0\n",
    "for c in w1y_qt_col:\n",
    "    feat = ['age','sex','agesex','age2','age2sex']\n",
    "    feat.append(c)\n",
    "    x_train = X_train[~X_train[c].isna()]\n",
    "    if x_train.shape[0]<10000:\n",
    "        continue\n",
    "    logit = sm.Logit(y_train[x_train.index], sm.add_constant(x_train[feat])).fit()\n",
    "    display(logit.summary())\n",
    "    count = count +1 \n",
    "    pval = logit.pvalues[c]\n",
    "    print(pval)\n",
    "    if pval < 0.05:\n",
    "        sign_count = sign_count+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)\n",
    "print(sign_count)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "pvalues_columns = []\n",
    "count = 0 \n",
    "sign_count = 0\n",
    "for c in extra_feat2:\n",
    "# for c in w1y_qt_col:\n",
    "    feat = ['age','sex','agesex','age2','age2sex']\n",
    "    feat.append(c)\n",
    "    x_train = X_train[~X_train[c].isna()]\n",
    "    if x_train.shape[0]<5000:\n",
    "        continue\n",
    "    logit = sm.Logit(y_train[x_train.index], sm.add_constant(x_train[feat])).fit()\n",
    "    display(logit.summary())\n",
    "    count = count +1 \n",
    "    pval = logit.pvalues[c]\n",
    "    print(pval)\n",
    "    pvalues.append(pval)\n",
    "    pvalues_columns.append(c)\n",
    "    if pval < 0.05:\n",
    "        sign_count = sign_count+1\n",
    "    \n",
    "    try:\n",
    "        feat = []\n",
    "        feat.extend(agesex)\n",
    "#         feat.extend(trad)\n",
    "#         feat.extend(tradextralog)\n",
    "        feat.extend(new_baseline)\n",
    "        out = pf.predict_cv(feat=feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lr',feat_sel_type = None)\n",
    "        pred_dict_cv['{}_base2_{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "  \n",
    "        feat.append(c)\n",
    "        out = pf.predict_cv(feat=feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lr',feat_sel_type = None)\n",
    "        pred_dict_cv['{}_base2plus{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "        \n",
    "#         GDF15 = ['GDF15']\n",
    "#         GDF15.extend(feat)\n",
    "#         out = pf.predict_cv(feat=GDF15,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lr',feat_sel_type = None)\n",
    "#         pred_dict_cv['{}_baseGDF15_{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "        \n",
    "#         protein_feat = []\n",
    "#         protein_feat.extend(boruta)\n",
    "#         protein_feat.extend(feat)\n",
    "#         out = pf.predict_cv(feat=protein_feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lrl1',feat_sel_type = None)\n",
    "#         pred_dict_cv['{}_baseprotein_{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "\n",
    "#         protein_feat = []\n",
    "#         protein_feat.extend(agesex)\n",
    "#         protein_feat.extend(boruta)\n",
    "# #         protein_feat.extend(feat)\n",
    "#         out = pf.predict_cv(feat=protein_feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lrl1',feat_sel_type = None)\n",
    "#         pred_dict_cv['{}_agesexprotein_{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "        \n",
    "        \n",
    "#         feat = []\n",
    "#         feat.extend(agesex)\n",
    "#         feat.extend(trad)\n",
    "#         feat.extend(tradextralog)\n",
    "#         feat.extend([c,c+'2',c+'age',c+'sex'])\n",
    "#         out = pf.predict_cv(feat=feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lrl2',feat_sel_type = None)\n",
    "#         pred_dict_cv['{}_{}_extra_lr_y{}'.format(dataset,c,k)] = out\n",
    "        \n",
    "#         feat = []\n",
    "#         feat.extend(agesex)\n",
    "#         feat.extend(trad)\n",
    "#         feat.extend(tradextralog)\n",
    "#         transformer = QuantileTransformer(n_quantiles=50000, output_distribution = 'normal',random_state=10)\n",
    "#         transformer.fit(np.array(x_train[c]).reshape(-1,1))\n",
    "#         x_train[c+'_qt'] = transformer.transform(np.array(x_train[c]).reshape(-1,1))\n",
    "#         feat.append(c+'_qt')\n",
    "#         out = pf.predict_cv(feat=feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lr',feat_sel_type = None)\n",
    "#         pred_dict_cv['{}_{}_qt_lr_y{}'.format(dataset,c,k)] = out        \n",
    "\n",
    "        f = open(folder+pred_folder+\"{}_{}_predict_trad_cv.pkl\".format(endpoint,dataset),\"wb\")\n",
    "        pickle.dump(pred_dict_cv,f)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Fail')\n",
    "pvalues = pd.DataFrame(pvalues,index=pvalues_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         f = open(folder+pred_folder+\"{}_{}_predict_trad_cv.pkl\".format(endpoint,dataset),\"wb\")\n",
    "#         pickle.dump(pred_dict_cv,f)\n",
    "#         f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicols = {'Bloodcells': ['Hematocrit_w1y', 'Hemoglobin_w1y','MCH_w1y','MCHC_w1y','MCV_w1y','Platelets_w1y','WBC_w1y','RDW_w1y'],#(RBC_w1y)\n",
    "             'Suggested': ['SBP','Glucose_w1y','Triglycerides_w1y'],\n",
    "             'Top3': ['ALP_w1y','ESR_w1y','RDW_w1y'],\n",
    "             'Top3+4High':['ALP_w1y','ESR_w1y','RDW_w1y','Fibrosis-4_w1y','Hematocrit_w1y', 'Hemoglobin_w1y','RBC_w1y'],\n",
    "             'Likely_candidates': ['SBP','Glucose_w1y','Triglycerides_w1y','HDL','TC','Creatinine_w1y'],\n",
    "             'CV_risk': ['SBP','HDL','TC']}\n",
    "\n",
    "included_names = ['Bloodcells','Likely3','Top3','High7','Likely6','CV risk']\n",
    "#              'reviewer_nw1y': ['SBP','Glucose','Triglycerides'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1y_qt_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c,val in multicols.items():\n",
    "# for c in w1y_qt_col:    \n",
    "    print(c)\n",
    "    print(val)\n",
    "    x_train = X_train[(~X_train[val].isna()).all(axis=1)]\n",
    "    print(x_train.shape)\n",
    "#     if x_train.shape[0]<5000:\n",
    "#         continue\n",
    "    try:\n",
    "        feat = []\n",
    "        feat.extend(agesex)\n",
    "#         feat.extend(trad)\n",
    "#         feat.extend(tradextralog)\n",
    "        feat.extend(new_baseline)\n",
    "        out = pf.predict_cv(feat=feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lrl2',feat_sel_type = None)\n",
    "        pred_dict_cv['{}_base2_{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "        \n",
    "        feat.extend(val)\n",
    "        out = pf.predict_cv(feat=feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lrl2',feat_sel_type = None)\n",
    "        pred_dict_cv['{}_base2plus{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "        \n",
    "#         protein_feat = []\n",
    "#         protein_feat.extend(boruta)\n",
    "#         protein_feat.extend(feat)\n",
    "#         out = pf.predict_cv(feat=protein_feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lrl1',feat_sel_type = None)\n",
    "#         pred_dict_cv['{}_baseprotein_{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "        \n",
    "#         protein_feat = []\n",
    "#         protein_feat.extend(boruta)\n",
    "#         protein_feat.extend(agesex)\n",
    "#         out = pf.predict_cv(feat=protein_feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lrl1',feat_sel_type = None)\n",
    "#         pred_dict_cv['{}_agesexprotein_{}_lr_y{}'.format(dataset,c,k)] = out\n",
    "        \n",
    "        \n",
    "#         transformer = QuantileTransformer(n_quantiles=50000, output_distribution = 'normal',random_state=10)\n",
    "#         transformer.fit(np.array(x_train[c]).reshape(-1,1))\n",
    "#         x_train[c+'_qt'] = transformer.transform(np.array(x_train[c]).reshape(-1,1))\n",
    "#         feat.append(c+'_qt')\n",
    "#         out = pf.predict_cv(feat=feat,kf=kf,X=x_train,y=y[k][x_train.index],model_type = 'lr',feat_sel_type = None)\n",
    "#         pred_dict_cv['{}_{}_qt_lr_y{}'.format(dataset,c,k)] = out        \n",
    "\n",
    "        f = open(folder+pred_folder+\"{}_{}_predict_trad_cv.pkl\".format(endpoint,dataset),\"wb\")\n",
    "        pickle.dump(pred_dict_cv,f)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(folder+pred_folder+\"{}_{}_predict_trad_cv.pkl\".format(endpoint,dataset),\"wb\")\n",
    "# pickle.dump(pred_dict_cv,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_qt = []\n",
    "for c in w1y_qt_col:\n",
    "    x_train = X_train[~X_train[c].isna()]\n",
    "    if x_train.shape[0]<5000:\n",
    "        continue\n",
    "    inc_qt.append(c)\n",
    "len(inc_qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_feat=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Featutes in the big picture\n",
    "all_extra_feat = extra_feat2[1:]+list(w1y_qt_col)\n",
    "all_extra_feat.remove('HDL_w1y')\n",
    "all_extra_feat.remove('Total_cholesterol_w1y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select which one of the plots to make\n",
    "\n",
    "all_extra_feat_N = []\n",
    "all_extra_feat_case = []\n",
    "\n",
    "### Addin one feature at a time\n",
    "if single_feat:\n",
    "    included_names = []\n",
    "    for c in all_extra_feat:\n",
    "        x_train = X_train[~X_train[c].isna()]\n",
    "        if x_train.shape[0]<5000:\n",
    "            continue\n",
    "        all_extra_feat_N.append(x_train.shape[0])\n",
    "        all_extra_feat_case.append(y[k][x_train.index].sum())\n",
    "        if 'w1y' in c:\n",
    "            c = c.replace('_w1y','')\n",
    "        included_names.append(c)\n",
    "    \n",
    "### Add combination of features\n",
    "else:    \n",
    "    for c, val in multicols.items():\n",
    "        x_train = X_train[(~X_train[val].isna()).all(axis=1)]\n",
    "        all_extra_feat_N.append(x_train.shape[0])\n",
    "        all_extra_feat_case.append(y[k][x_train.index].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(folder+org_folder+\"{}_{}_predict_trad_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "pred_dict_org_cv = pickle.load(file)\n",
    "list(pred_dict_org_cv.keys())\n",
    "\n",
    "for key, value in pred_dict_org_cv.items():\n",
    "    if 'agesex' in key:\n",
    "        print(key)\n",
    "        pred_dict_cv[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=4\n",
    "keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "I_train = I_train_main.intersection(keep_samples)\n",
    "I_test = I_test_main.intersection(keep_samples)\n",
    "tte_train = time_to_event[I_train]\n",
    "score_dict = {}\n",
    "base_score_dict = {}\n",
    "protein_score_dict = {}\n",
    "include_protein = True\n",
    "# try: \n",
    "#     file = open(folder+pred_folder+\"{}_{}_predict_trad_cv.pkl\".format(endpoint,dataset),'rb')\n",
    "#     pred_dict_cv = pickle.load(file)\n",
    "\n",
    "# except:\n",
    "#     pred_dict_cv = {}\n",
    "\n",
    "keys = pred_dict_cv.keys()\n",
    "# print(keys)\n",
    "\n",
    "\n",
    "included_qt = []\n",
    "bins = [0,0.075,1]\n",
    "# for c, val in multicols.items():\n",
    "# for c in w1y_qt_col:\n",
    "for c in all_extra_feat:\n",
    "# for c in extra_feat:\n",
    "# for c in pvalues_columns:\n",
    "\n",
    "    if single_feat:\n",
    "        x_train_index = X_train.index[~X_train[c].isna()]\n",
    "        if len(x_train_index)<5000:\n",
    "            continue\n",
    "    else:\n",
    "        x_train_index = X_train.index[(~X_train[val].isna()).all(axis=1)]\n",
    "\n",
    "    included_qt.append(c)\n",
    "#     key = '{}_{}_lr_y{}'.format(dataset,c,k)\n",
    "    key = '{}_base2plus{}_lr_y{}'.format(dataset,c,k)\n",
    "\n",
    "    out = []\n",
    "    base_out = []\n",
    "    protein_out = []\n",
    "    fold_num = 0\n",
    "    for train_index, test_index in kf.split(x_train_index):\n",
    "        fold = pred_dict_cv[key][2][fold_num]\n",
    "        numf = pred_dict_cv[key][0][fold_num]\n",
    "        y_test = y[k][x_train_index].iloc[test_index]\n",
    "#         tte_test = tte_train.iloc[test_index]\n",
    "#         base_fold = pred_dict_cv['{}_agesex_lr_y{}'.format(dataset,k)][2][fold_num]        \n",
    "#         base_fold = pred_dict_cv['{}_base_{}_lr_y{}'.format(dataset,c,k)][2][fold_num] \n",
    "        base_fold = pred_dict_cv['{}_base2_{}_lr_y{}'.format(dataset,c,k)][2][fold_num] \n",
    "        if include_protein: \n",
    "            protein_fold = pred_dict_cv['{}_agesexprotein_{}_lr_y{}'.format(dataset,c,k)][2][fold_num]  \n",
    "#         y_cens_test = y_cens[k][I_train].iloc[test_index]\n",
    "#         print(key)\n",
    "        auc =[]\n",
    "        base_auc = []\n",
    "        protein_auc = []\n",
    "        for i,case in enumerate(fold):\n",
    "            auc.append(len(numf[i]))\n",
    "#             auc.extend(calculate_metrics(np.array(case).reshape(-1)[~y_cens_test],np.array(base_fold[0]).reshape(-1)[~y_cens_test],y_test[~y_cens_test],bins=bins))\n",
    "            auc.extend(calculate_metrics(np.array(case).reshape(-1),np.array(base_fold[0]).reshape(-1),y_test,bins=bins))\n",
    "    \n",
    "            base_auc.append(len(numf[i])-1)\n",
    "            base_auc.extend(calculate_metrics(np.array(base_fold[0]).reshape(-1),np.array(base_fold[0]).reshape(-1),y_test,bins=bins))\n",
    "            if include_protein:\n",
    "                protein_auc.append(len(numf[i])-1)\n",
    "                protein_auc.extend(calculate_metrics(np.array(protein_fold[0]).reshape(-1),np.array(base_fold[0]).reshape(-1),y_test,bins=bins))\n",
    "\n",
    "        \n",
    "        out.append(auc)\n",
    "        base_out.append(base_auc)\n",
    "        if include_protein:\n",
    "            protein_out.append(protein_auc)\n",
    "        fold_num = fold_num+1\n",
    "    score_dict[key] = out\n",
    "    base_score_dict[key] = base_out\n",
    "    if include_protein:\n",
    "        protein_score_dict[key] = protein_out\n",
    "#             print(len(y_test), len(case))\n",
    "# f = open(folder+pred_folder+\"{}_{}_score_cv.pkl\".format(endpoint,dataset),\"wb\")\n",
    "# pickle.dump(score_dict,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERY_SMALL_SIZE = 12\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=VERY_SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = score_dict.keys()\n",
    "if single_feat:\n",
    "    fig = plt.figure(figsize=[15,6])\n",
    "else:\n",
    "    fig = plt.figure(figsize=[6,6])\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax2 = ax.twinx()\n",
    "# fig = plt.figure(figsize=[12,6])\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    base_out = base_score_dict[key]\n",
    "    protein_out = protein_score_dict[key]\n",
    "#     plt.scatter(np.array(out).mean(axis=0)[:,0],np.array(out).mean(axis=0)[:,1])\n",
    "    ax.scatter(i,np.array(out).mean(axis=0)[1]-np.array(base_out).mean(axis=0)[1],color='blue')\n",
    "    ax.scatter(i,np.array(protein_out).mean(axis=0)[1]-np.array(base_out).mean(axis=0)[1],color='red')\n",
    "    ax2.bar(i,all_extra_feat_N[i],color = 'black',alpha=0.2)\n",
    "    ax2.bar(i,all_extra_feat_case[i],color = 'red',alpha=0.2)\n",
    "ax.grid()\n",
    "ax.set_xticks(ticks = range(len(included_qt)))\n",
    "# ax.set_xticklabels(labels=included_qt, rotation = 90)\n",
    "ax.set_xticklabels(labels=included_names, rotation = 90)\n",
    "ax.legend(['Baseline+feature','Age+sex+proteins'])\n",
    "ax2.legend(['N','Cases'],loc='upper left',bbox_to_anchor=(1.0, 1.0))\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('Model AUC - Baseline AUC')\n",
    "ax2.set_ylabel('Number of samples')\n",
    "\n",
    "plt.title('Ten-fold CV, 5-year mortality risk')\n",
    "# lgd = plt.legend(keys,loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "if single_feat:\n",
    "    plt.savefig(folder+pred_folder+\"{}_{}_AUC_diff_wN_y{}_base2_extra_all.png\".format(endpoint,dataset,k), bbox_inches='tight')\n",
    "else:\n",
    "    plt.savefig(folder+pred_folder+\"{}_{}_AUC_diff_wN_y{}_base2_extra_multicol.png\".format(endpoint,dataset,k), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = pred_dict_cv.keys()\n",
    "keys = score_dict.keys()\n",
    "# fig = plt.figure(figsize=[6,6])\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    base_out = base_score_dict[key]\n",
    "#     plt.scatter(np.array(out).mean(axis=0)[:,0],np.array(out).mean(axis=0)[:,1])\n",
    "    plt.scatter(i,np.array(out).mean(axis=0)[1]-np.array(base_out).mean(axis=0)[1])\n",
    "\n",
    "lgd = plt.legend(keys,loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "# plt.savefig(folder+\"Predictions_cv/{}_{}_AUC_y{}.png\".format(endpoint,dataset,k), bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=[12,6])\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    plt.scatter(i,np.array(out).mean(axis=0)[1])\n",
    "# plt.legend(keys)\n",
    "lgd = plt.legend(keys,loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "# plt.savefig(folder+pred_folder+\"{}_{}_logloss_y{}.png\".format(endpoint,dataset,k),bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = score_dict.keys()\n",
    "print(keys)\n",
    "fig = plt.figure(figsize=[15,6])\n",
    "# fig = plt.figure(figsize=[12,6])\n",
    "for i,key in enumerate(keys):\n",
    "    out=score_dict[key]\n",
    "    base_out = base_score_dict[key]\n",
    "#     protein_out = protein_score_dict[key]\n",
    "#     plt.scatter(np.array(out).mean(axis=0)[:,0],np.array(out).mean(axis=0)[:,1])\n",
    "    plt.scatter(i,np.array(out).mean(axis=0)[1]-np.array(base_out).mean(axis=0)[1],color='blue')\n",
    "    plt.scatter(i,np.array(protein_out).mean(axis=0)[1]-np.array(base_out).mean(axis=0)[1],color='red')\n",
    "plt.grid()\n",
    "plt.xticks(ticks = range(len(included_qt)),labels=included_qt, rotation = 90)\n",
    "plt.legend(['Baseline+risk factor','Age+sex+proteins'])\n",
    "plt.xlabel('Dataset/ Risk factor')\n",
    "plt.ylabel('Model AUC - baseline AUC')\n",
    "plt.title('Ten-fold CV, 5-year mortality risk')\n",
    "# lgd = plt.legend(keys,loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "# plt.savefig(folder+pred_folder+\"{}_{}_AUC_diff_y{}_extra_all.png\".format(endpoint,dataset,k), bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((~X_train[pvalues_columns].isna()).all(axis=1).sum())\n",
    "# print((~X_train[important_qt].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Hematocrit_w1y', 'Hemoglobin_w1y','RDW_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Creatinine_w1y','SBP','Glucose_w1y','HDL','Platelets_w1y','Triglycerides_w1y','ESR_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Creatinine_w1y','Platelets_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Creatinine_w1y','Platelets_w1y','ESR_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Creatinine_w1y','Platelets_w1y','ESR_w1y','Hematocrit_w1y', 'Hemoglobin_w1y','RDW_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Creatinine_w1y','Platelets_w1y','Hematocrit_w1y', 'Hemoglobin_w1y','RDW_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Creatinine_w1y','SBP','Glucose_w1y','HDL','Triglycerides_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['SBP','Glucose_w1y','Triglycerides_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['SBP','Glucose_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['SBP','Glucose','Triglycerides']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Hematocrit_w1y', 'Hemoglobin_w1y','MCH_w1y','MCHC_w1y','MCV_w1y','Platelets_w1y','WBC_w1y','RDW_w1y']].isna()).all(axis=1).sum()) ### All bood cell counts\n",
    "print((~X_train[['ALP_w1y','ESR_w1y','RDW_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['ALP_w1y','ESR_w1y','RDW_w1y','Fibrosis-4_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['ALP_w1y','ESR_w1y','RDW_w1y','Fibrosis-4_w1y','Hematocrit_w1y', 'Hemoglobin_w1y','RBC_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['Creatinine_w1y','Glucose_w1y','Platelets_w1y','Triglycerides_w1y','ESR_w1y']].isna()).all(axis=1).sum())\n",
    "print((~X_train[['SBP','Glucose_w1y','Triglycerides_w1y','HDL','TC','Creatinine_w1y']].isna()).all(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Hematocrit_w1y', 'Hemoglobin_w1y','RDW_w1y']\n",
    "['Creatinine_w1y','SBP','Glucose_w1y','non_HDL','Platelets_w1y','Triglycerides_w1y']\n",
    "important_qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~X_train[pvalues_columns].isna()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
