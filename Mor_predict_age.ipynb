{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix, log_loss\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LassoCV\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFE, RFECV, SelectPercentile, SelectFpr, SelectFdr, SelectFwe\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import pearsonr\n",
    "import sys\n",
    "sys.path.append('/odinn/users/thjodbjorge/Python_functions/')\n",
    "import Predict_functions as pf\n",
    "from Calculate_score import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/odinn/users/thjodbjorge/Proteomics/Mortality2/'\n",
    "feat_folder = 'Features2/'\n",
    "pred_folder = 'Predictions3/'\n",
    "# corr_type = 'sitesampleageqt'\n",
    "corr_type = 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if corr_type == 'qt':\n",
    "    print('Load qt transformed proteins')\n",
    "    proteins = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/protein_data/protein_qt.csv',index_col = 'Barcode2d' )\n",
    "else:\n",
    "    print('Load raw protein values')\n",
    "    raw_data = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/raw_with_info.csv',index_col = 'Barcode2d' )\n",
    "    \n",
    "probe_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probe_info.csv', index_col = 'SeqId')\n",
    "\n",
    "pn_info = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/pn_info_Mor/pn_info_Mor_event.csv',index_col = 'Barcode2d' )\n",
    "probes_to_skip = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/Data/probes_to_skip.txt')['probe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if corr_type == 'pqtl':\n",
    "    pqtl_protein = pd.read_csv('/odinn/users/egilf/pQTL/for_benedikt/pQTL_conditional_04052020.gor', sep='\\t')\n",
    "    # pqtl = pd.read_csv('/odinn/users/steinthora/proteomics/proteomic_project/Data/pQTL_Merged_08052020.csv', sep = '\\t', index_col = 'PN')\n",
    "    pqtl = pd.read_csv('/odinn/users/thjodbjorge/Proteomics/pqtl/pqtl_combined_meanimp.csv',index_col = 'PN')\n",
    "\n",
    "\n",
    "    # In[4]:\n",
    "\n",
    "    pqtl = pd.merge(pn_info['PN'],pqtl,left_on='PN',right_index=True)\n",
    "    pqtl.drop('PN',axis=1,inplace=True)\n",
    "    pro_pqtl = {}\n",
    "    for i in raw_data.iloc[:,16:].columns:\n",
    "        pro_pqtl[i] = list(pqtl_protein[pqtl_protein.SeqId == i[6:].replace('-','_')]['SentinelMarker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = 'age'\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=10, shuffle=False) \n",
    "I_train_main, I_test_main = train_test_split(pn_info.index, train_size=0.7, random_state = 10)\n",
    "# I_val_main, I_test_main = train_test_split(I_test_main, train_size=0.5, random_state = 10)\n",
    "\n",
    "\n",
    "\n",
    "file = open(folder+\"{}_keep_samples.pkl\".format('Mor'),'rb')\n",
    "keep_samples_dict = pickle.load(file)\n",
    "\n",
    "# print(keep_samples_dict.keys())\n",
    "# keep_samples_keys = ['Old_18105', 'Old_60105', 'Old_6080','Old_18105_C', 'Old_18105_I', 'Old_18105_J', 'Old_18105_G','Old_18105_Other']\n",
    "keep_samples_keys = ['Old_18105']#,'Old_60105']\n",
    "# keep_samples_keys = ['Old_18105_Neoplasms','Old_18105_I','Old_18105_J','Old_18105_G','Old_18105_Other']\n",
    "skip_PC = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in keep_samples_keys:\n",
    "\n",
    "    print(dataset)\n",
    "    keep_samples = keep_samples_dict[dataset]\n",
    "\n",
    "    I_train = I_train_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "    I_test = I_test_main.intersection(keep_samples)#.intersection(have_prs)\n",
    "        # ### Select data and normalize\n",
    "\n",
    "    if corr_type == 'qt':\n",
    "        X = proteins\n",
    "    else:\n",
    "        X = np.log(raw_data.iloc[:,16:].drop(probes_to_skip,axis=1))\n",
    "\n",
    "    all_protein = X.columns\n",
    "    X['sex'] = pn_info[['sex']].values-1\n",
    "    X['age'] = pn_info[['Age_at_sample_collection_2']].values\n",
    "\n",
    "    X['age2'] = X['age']**2\n",
    "#     X['age3'] = X['age']**3\n",
    "    X['agesex'] = X['age']*X['sex']\n",
    "    X['age2sex'] = X['age2']*X['sex']\n",
    "        \n",
    "    agesex = ['age','sex','agesex','age2','age2sex']\n",
    "    \n",
    "    X['PAD'] = pn_info['PAD']\n",
    "    no_bmi = (X['PAD'].isna())\n",
    "    no_bmi_ind = X[no_bmi].index\n",
    "    X.loc[I_train.intersection(no_bmi_ind),'PAD'] = X.loc[I_train].PAD.mean()\n",
    "    X.loc[I_test.intersection(no_bmi_ind),'PAD'] = X.loc[I_test].PAD.mean()\n",
    "    \n",
    "    X['site'] = (pn_info['site'] == 'DC').astype(int)\n",
    "    X['Sample_age'] = pn_info['Sample_age']\n",
    "    try: \n",
    "        print('Load age dictonary')\n",
    "        file = open(folder+pred_folder+\"age_predict.pkl\",'rb')\n",
    "        age_dict = pickle.load(file)\n",
    "        file.close()\n",
    "        PAD2 = age_dict['{}_sexprotein_lasso'.format(dataset)][4]-X.age\n",
    "        X['PAD2'] = PAD2\n",
    "    except:\n",
    "        print('No file to load')\n",
    "    \n",
    "    X_train = X.loc[I_train]\n",
    "    X_test = X.loc[I_test]\n",
    "    \n",
    "\n",
    "            \n",
    "    if corr_type == 'sitesampleage':\n",
    "        print('Correct proteins fro site and sample age')\n",
    "        for p in all_protein:    \n",
    "            corr_model = sm.OLS(X_train[p],sm.add_constant(X_train[['site','Sample_age']])).fit()\n",
    "            corr_train = corr_model.predict(sm.add_constant(X_train[['site','Sample_age']]))\n",
    "            corr_test = corr_model.predict(sm.add_constant(X_test[['site','Sample_age']]))\n",
    "        #     corr_train.columns = all_protein\n",
    "            X_train[p] = X_train[p] - corr_train\n",
    "            X_test[p] = X_test[p] - corr_test\n",
    "        print('Correction done')     \n",
    "        \n",
    "        \n",
    "    if corr_type == 'sitesampleageqt':\n",
    "        print('Correct proteins for site and sample age')\n",
    "        for p in all_protein:    \n",
    "            corr_model = sm.OLS(X_train[p],sm.add_constant(X_train[['site','Sample_age']])).fit()\n",
    "            corr_train = corr_model.predict(sm.add_constant(X_train[['site','Sample_age']]))\n",
    "            corr_test = corr_model.predict(sm.add_constant(X_test[['site','Sample_age']]))\n",
    "        #     corr_train.columns = all_protein\n",
    "            X_train[p] = X_train[p] - corr_train\n",
    "            X_test[p] = X_test[p] - corr_test\n",
    "        print('Normalize proteins')    \n",
    "        transformer = QuantileTransformer(n_quantiles=50000, output_distribution = 'normal',random_state=10)\n",
    "        transformer.fit(X_train[all_protein])\n",
    "        X_train[all_protein] = transformer.transform(X_train[all_protein])\n",
    "        X_test[all_protein] = transformer.transform(X_test[all_protein]) \n",
    "        \n",
    "    if corr_type == 'batch':\n",
    "        for p in all_protein:    \n",
    "            corr_model = sm.OLS(X_train[p],sm.add_constant(X_train[batch_var])).fit()\n",
    "            corr_train = corr_model.predict(sm.add_constant(X_train[batch_var]))\n",
    "            corr_test = corr_model.predict(sm.add_constant(X_test[batch_var]))\n",
    "        #     corr_train.columns = all_protein\n",
    "            X_train[p] = X_train[p] - corr_train\n",
    "            X_test[p] = X_test[p] - corr_test           \n",
    "        \n",
    "    \n",
    "    if corr_type == 'PCA':\n",
    "        pca1 = PCA(skip_PC)\n",
    "        x_pca1 = pca1.fit_transform(X_train[all_protein])\n",
    "        x_1 = pca1.inverse_transform(x_pca1)\n",
    "        X_train[all_protein] = X_train[all_protein] - x_1\n",
    "\n",
    "        x_pca1 = pca1.transform(X_test[all_protein])\n",
    "        x_1 = pca1.inverse_transform(x_pca1)\n",
    "        X_test[all_protein] = X_test[all_protein] - x_1\n",
    "    \n",
    "    \n",
    "    train_mean = X_train.mean()\n",
    "    train_std = X_train.std()\n",
    "\n",
    "    X_train = (X_train-train_mean)/train_std\n",
    "    X_test = (X_test-train_mean)/train_std\n",
    "\n",
    "    print('Done')\n",
    "    \n",
    "    try: \n",
    "        print('Load prediction dictonary')\n",
    "        file = open(folder+pred_folder+\"{}_predict.pkl\".format(endpoint),'rb')\n",
    "        pred_dict = pickle.load(file)\n",
    "        file.close()\n",
    "    except:\n",
    "        print('No file to load')\n",
    "        pred_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['PAD2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(X_train.PAD,X_train.PAD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X.loc[I_train,endpoint]\n",
    "y_test = X.loc[I_test,endpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat = ['sex']\n",
    "feat.extend(all_protein)\n",
    "model = LassoCV(cv = 5,n_jobs=-1)\n",
    "model.fit(X_train[feat],y_train)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.alphas_,model.mse_path_.mean(axis=1))\n",
    "print(model.score(X_train[feat],y_train))\n",
    "print(model.score(X_test[feat],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X[feat] - train_mean[feat])/train_std[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_pred = model.predict(X_train[feat])\n",
    "test_pred = model.predict(X_test[feat])\n",
    "pred_all = model.predict((X[feat] - train_mean[feat])/train_std[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(y_train,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(endpoint)\n",
    "plt.scatter(X.age,pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict['{}_sexprotein_lasso'.format(dataset)] = model,train_pred,test_pred, feat, pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(folder+pred_folder+\"{}_predict.pkl\".format(endpoint),\"wb\")\n",
    "pickle.dump(pred_dict,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(y_train+X['PAD'][I_train],train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(X['PAD'][I_train],train_pred-y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(feat)[np.abs(model.coef_) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(folder+pred_folder+\"{}_predict.pkl\".format(endpoint),\"wb\")\n",
    "# pickle.dump(pred_dict,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(['P00533',\n",
    "'P61769',\n",
    "'Q2UY09',\n",
    "'P49755',\n",
    "'Q76LX8',\n",
    "'Q9GZX9',\n",
    "'Q9H4F8',\n",
    "'P07949',\n",
    "'Q92626',\n",
    "'Q9Y5H3',\n",
    "'P01034',\n",
    "'P19438',\n",
    "'Q8WWX9',\n",
    "'P20333',\n",
    "'Q01974',\n",
    "'Q96DX5',\n",
    "'Q9BXY4',\n",
    "'P21757',\n",
    "'P07998',\n",
    "'Q99988',\n",
    "'O00300',\n",
    "'P45379',\n",
    "'Q13790',\n",
    "'Q01995',\n",
    "'Q12805',\n",
    "'Q4LDE5',\n",
    "'Q9NP99',\n",
    "'Q9H5V8',\n",
    "'O76076',\n",
    "'Q2I0M5',\n",
    "'O95633',\n",
    "'Q96GP6',\n",
    "'Q9BU40',\n",
    "'P41222',\n",
    "'P21246'],columns = ['UniProt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_info.UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(probe_info.reset_index()[['SeqId','UniProt','TargetFullName']],how='left',left_on='UniProt',right_on='UniProt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_info.reset_index()[['SeqId','UniProt','TargetFullName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
